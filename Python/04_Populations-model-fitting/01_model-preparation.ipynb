{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is the last step in preparing the data the Random Forest Regressors for Each population to Predict Biomass\n",
    "\n",
    " Here we will seperate the dataframes by population, prepare split features (variables used for prediction) and the label (what we are trying to predict, biomass).\n",
    "\n",
    "This notebook also includes a few functions we will use within the notebook and within each population's random forest model building notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set a working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a working directory\n",
    "#!pip install GitPython\n",
    "import git\n",
    "import os\n",
    "\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "\n",
    "\n",
    "os.chdir(repo.working_tree_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cruise</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>abundance_pro</th>\n",
       "      <th>abundance_syn</th>\n",
       "      <th>abundance_pico</th>\n",
       "      <th>abundance_croco</th>\n",
       "      <th>biomass_pro</th>\n",
       "      <th>biomass_syn</th>\n",
       "      <th>...</th>\n",
       "      <th>sss</th>\n",
       "      <th>sst</th>\n",
       "      <th>ugos</th>\n",
       "      <th>vgos</th>\n",
       "      <th>Fe</th>\n",
       "      <th>O2</th>\n",
       "      <th>NO3</th>\n",
       "      <th>PO4</th>\n",
       "      <th>Si</th>\n",
       "      <th>hours_since_sunrise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-22 22:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.343400</td>\n",
       "      <td>-158.273700</td>\n",
       "      <td>135.216812</td>\n",
       "      <td>2.021318</td>\n",
       "      <td>1.456863</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>4.024661</td>\n",
       "      <td>0.337763</td>\n",
       "      <td>...</td>\n",
       "      <td>34.571716</td>\n",
       "      <td>25.653118</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>-0.132531</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>6.129444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-22 23:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.343533</td>\n",
       "      <td>-158.273744</td>\n",
       "      <td>136.856649</td>\n",
       "      <td>2.437622</td>\n",
       "      <td>1.774607</td>\n",
       "      <td>0.007009</td>\n",
       "      <td>4.167834</td>\n",
       "      <td>0.413687</td>\n",
       "      <td>...</td>\n",
       "      <td>34.571716</td>\n",
       "      <td>25.653118</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>-0.132531</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>7.129444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-23 00:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.346175</td>\n",
       "      <td>-158.274150</td>\n",
       "      <td>130.873523</td>\n",
       "      <td>3.810792</td>\n",
       "      <td>2.018130</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>4.654360</td>\n",
       "      <td>0.654208</td>\n",
       "      <td>...</td>\n",
       "      <td>34.609317</td>\n",
       "      <td>25.646243</td>\n",
       "      <td>-0.002256</td>\n",
       "      <td>-0.132022</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>8.129722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  cruise        lat         lon  abundance_pro  \\\n",
       "0 2015-05-22 22:00:00  KM1508  21.343400 -158.273700     135.216812   \n",
       "1 2015-05-22 23:00:00  KM1508  21.343533 -158.273744     136.856649   \n",
       "2 2015-05-23 00:00:00  KM1508  21.346175 -158.274150     130.873523   \n",
       "\n",
       "   abundance_syn  abundance_pico  abundance_croco  biomass_pro  biomass_syn  \\\n",
       "0       2.021318        1.456863         0.006307     4.024661     0.337763   \n",
       "1       2.437622        1.774607         0.007009     4.167834     0.413687   \n",
       "2       3.810792        2.018130         0.006307     4.654360     0.654208   \n",
       "\n",
       "   ...        sss        sst      ugos      vgos        Fe          O2  \\\n",
       "0  ...  34.571716  25.653118  0.005764 -0.132531  0.000088  216.794167   \n",
       "1  ...  34.571716  25.653118  0.005764 -0.132531  0.000088  216.794167   \n",
       "2  ...  34.609317  25.646243 -0.002256 -0.132022  0.000088  216.794167   \n",
       "\n",
       "            NO3       PO4        Si  hours_since_sunrise  \n",
       "0  4.269278e-07  0.345151  9.464704             6.129444  \n",
       "1  4.269278e-07  0.345151  9.464704             7.129444  \n",
       "2  4.269278e-07  0.345151  9.464704             8.129722  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "covari_path = 'data/modified/RF_ready_covari.csv'\n",
    "#using pandas to read in as a df\n",
    "covari = (pd.read_csv(covari_path,parse_dates=[0]))\n",
    "#taking a peak at the data\n",
    "covari.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have data for 4 types of phytoplankton, here we will split the df into one df per population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "covari_pro = covari.drop(columns=['biomass_pico','biomass_croco','biomass_syn','abundance_pico','abundance_croco','abundance_syn'])\n",
    "covari_syn = covari.drop(columns=['biomass_pico','biomass_croco','biomass_pro','abundance_pico','abundance_croco','abundance_pro'])\n",
    "covari_pico = covari.drop(columns=['biomass_syn','biomass_croco','biomass_pro','abundance_syn','abundance_croco','abundance_pro'])\n",
    "covari_croco = covari.drop(columns=['biomass_pico','biomass_syn','biomass_pro','abundance_pico','abundance_syn','abundance_pro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_dfer(covari_pop, pop_name):\n",
    "    \"\"\"\n",
    "    This function removes population names from the columns of each df\n",
    "    \"\"\"\n",
    "    df = covari_pop\n",
    "    pop_name = pop_name\n",
    "    df.rename(columns=lambda x: x.replace('_'+pop_name, ''), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing population names so columns are consistent accross dataframes\n",
    "population_dfer(covari_syn, 'syn')\n",
    "population_dfer(covari_pro, 'pro')\n",
    "population_dfer(covari_pico, 'pico')\n",
    "population_dfer(covari_croco, 'croco')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping abundance columns since we will just be predicting on biomass for now\n",
    "covari_pro.drop(columns=['abundance'], inplace=True)\n",
    "covari_syn.drop(columns=['abundance'], inplace=True)\n",
    "covari_pico.drop(columns=['abundance'], inplace=True)   \n",
    "covari_croco.drop(columns=['abundance'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'cruise', 'lat', 'lon', 'biomass', 'ALK', 'sss', 'sst', 'ugos',\n",
      "       'vgos', 'Fe', 'O2', 'NO3', 'PO4', 'Si', 'hours_since_sunrise'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(covari_pro.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_single_population(covari_population):\n",
    "    \"\"\"\n",
    "    Takes the covari dataframe, and whichever of the four populations and returns a dataframe that\n",
    "    only includes the selected population's rows, a list of labels (biomass values associated with the dataframe)\n",
    "    and a list of all of the features.\n",
    "    \"\"\"\n",
    "    # Selecting the population based on the provided name\n",
    "    pop_df = covari_population\n",
    "\n",
    "    # Creating the labels and features for the population\n",
    "    labels = np.array(pop_df.biomass)\n",
    "    labels = np.delete(labels, 0, 0)\n",
    "    features = pop_df.drop(['time', 'biomass', 'lat', 'lon', 'cruise'], axis=1)\n",
    "    # Saving feature names for later use\n",
    "    feature_list = list(features.columns)\n",
    "    features = features.to_numpy()\n",
    "    features = np.delete(features, 0, 0)\n",
    "    return pop_df, labels, features, feature_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the preprocess_single_population function for all of the populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4679, 11)\n",
      "<class 'numpy.ndarray'>\n",
      "(4679,)\n"
     ]
    }
   ],
   "source": [
    "# creating a df, labels and features with only for the observed Prochlorooccus\n",
    "\n",
    "\n",
    "pro_df, labels_pro, features_pro, feature_list_pro = preprocess_single_population(covari_pro)\n",
    "# Checking length and type to make sure our model can process them\n",
    "print(features_pro.shape)\n",
    "print(type(features_pro))\n",
    "print(labels_pro.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a df, labels and features with only for the observed Synechoccoccus\n",
    "\n",
    "\n",
    "syn_df, labels_syn, features_syn, feature_list_syn = preprocess_single_population(covari_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a df, labels and features with only for the observed Picoeukaryotes\n",
    "\n",
    "\n",
    "pico_df, labels_pico, features_pico, feature_list_pico = preprocess_single_population(covari_pico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a df, labels and features with only for the observed Nanoeukaryotes\n",
    "\n",
    "\n",
    "croco_df, labels_croco, features_croco, feature_list_croco = preprocess_single_population(covari_croco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a function for finding the optimal testing to training ratio\n",
    "\n",
    "Used in specific random forest model notebooks. This function graphs the Root Mean Square Error (RMSE) vs. the testing to training ratio for data used in the model. The aim is to choose the highest testing to training ratio where the RMSE starts to fall most dramatically in value. Keeping a higher testing to training ratio keeps our model more  generalizable and prevents overfitting.  This function is called in each population specific notebook to find the optimal testing to training ratio for that population's model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def testing_training_ratio(features, labels, feature_list, title_prefix):\n",
    "    \"\"\"\n",
    "    This function uses K-fold cross validation to split the training set, each population specific notebook will use this function\n",
    "    \"\"\"\n",
    "    # Graphs the RMSE of different testing and training ratios\n",
    "    RMSEs = {'Test_Ratio':[], 'RMSE': []}\n",
    "    #define number of folds to try\n",
    "    splits = [2,4,6,8,12,16]\n",
    "    # Loop through the number of splits\n",
    "    for n in splits:\n",
    "        n_splits = n\n",
    "        kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "        #finding RMSEs for each fold\n",
    "        for train_index, test_index in kf.split(features):\n",
    "            train_features, test_features = features[train_index], features[test_index]\n",
    "            train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "\n",
    "            rf = RandomForestRegressor(n_estimators = 80, max_depth= 20, max_features='sqrt', random_state = 42)\n",
    "            rf.fit(train_features, train_labels)\n",
    "\n",
    "            # Use the forest's predict method on the test data\n",
    "            predictions = rf.predict(test_features)\n",
    "\n",
    "            # Calculate the absolute errors\n",
    "            errors = abs(predictions - test_labels)\n",
    "\n",
    "            # Finding the root mean square error (RMSE)\n",
    "            RMSE = mean_squared_error(test_labels, predictions, squared=False) #setting squared=False gives us RMSE not MSE\n",
    "            RMSEs['RMSE'].append(RMSE)\n",
    "            RMSEs['Test_Ratio'].append(1/n_splits)  # The test ratio for n-fold cross-validation is 1/n_splits\n",
    "   \n",
    "    # Extract Test Ratios and RMSEs from the dictionary\n",
    "    test_ratios = RMSEs['Test_Ratio']\n",
    "    rmse_values = RMSEs['RMSE']\n",
    "\n",
    "    # Create a line plot\n",
    "    plt.figure(figsize=(10, 6))  \n",
    "    plt.plot(test_ratios, rmse_values, marker='o')\n",
    "\n",
    "    # Fill the area under the curve\n",
    "    plt.fill_between(test_ratios, rmse_values, alpha=0.3)\n",
    "    \n",
    "    plt.xlabel('Testing:Training Ratio', fontsize=15)\n",
    "    plt.ylabel('RMSE of Biomass (pgC/L)fn', fontsize=15)\n",
    "    plt.title(f\"{title_prefix} - RMSE of Biomass vs. Testing: Training Ratio\", fontsize=22)\n",
    "\n",
    "    plt.xlim(0, 1)  \n",
    "    \n",
    "    plt.xticks([i/10 for i in range(11)])  # Set the x-axis tick locations at 0.1 increments\n",
    "    plt.gca().invert_xaxis()\n",
    "\n",
    "    \n",
    "    plt.grid(True) \n",
    "    \n",
    "    plt.tight_layout()  # Improves spacing between the plot elements\n",
    "    plt.savefig(f\"figures/{title_prefix}/RMSEsByFolds.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    return RMSEs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_training_ratio_random(features, labels, feature_list, title_prefix):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import matplotlib.pyplot as plt\n",
    "    \"\"\"\n",
    "    Used in specific random forest model notebooks. This function graphs the Root Mean Square Error (RMSE) vs.\n",
    "    the ratio to testing to training data. Aim is to choose the highest testing to training ratio where the RMSE\n",
    "    starts to fall most dramatically in value. Keeping a higher testing to training ratio keeps our model more\n",
    "    generalizable prevent overfitting.\n",
    "    \"\"\"\n",
    "    # Graphs the RMSE of differnt testing and training ratios\n",
    "    RMSEs = {'Test_Ratio':[], 'RMSE': []}\n",
    "    \n",
    "    range_list = [i / 20.0 for i in range(1, 19)] + [0.9][:-1] #prints 0.9 twice so I use all but last value\n",
    "\n",
    "    for fifth in range_list:\n",
    "        fifth = round(fifth, ndigits=2)\n",
    "        RMSEs['Test_Ratio'].append(fifth)\n",
    "        #using train_test_split to manipulate the training to testing ratio\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "            features, labels, test_size = fifth, random_state = 42\n",
    "            \n",
    "        )\n",
    "        rf = RandomForestRegressor(n_estimators = 80, max_depth = 10, max_features='sqrt', random_state = 42)\n",
    "        rf.fit(train_features, train_labels)\n",
    "        \n",
    "        \n",
    "        # Convert test_features to a DataFrame\n",
    "        test_features_df = pd.DataFrame(test_features, columns=feature_list)\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions = rf.predict(test_features)\n",
    "\n",
    "        # Create a new Series with predicted values and index from test_features_df\n",
    "        predic_biomass = pd.Series(predictions, index=test_features_df.index)\n",
    "\n",
    "        # Assign the new Series to the DataFrame using .loc\n",
    "        test_features_df.loc[:, 'Prediction'] = predic_biomass\n",
    "\n",
    "        # Calculate the absolute errors\n",
    "        errors = abs(predictions - test_labels)\n",
    "\n",
    "        # Finding the root mean square error (RMSE)\n",
    "\n",
    "        # RMSE give realtively high weight to large errors \n",
    "        RMSE = mean_squared_error(test_labels, predictions, squared=False) #setting squared=False gives us RMSE not MSE\n",
    "        RMSEs['RMSE'].append(RMSE)\n",
    "        \n",
    "    \n",
    "    # Extract Test Ratios and RMSEs from the dictionary\n",
    "    test_ratios = RMSEs['Test_Ratio']\n",
    "    rmse_values = RMSEs['RMSE']\n",
    "\n",
    "    # Create a line plot\n",
    "    plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "    plt.plot(test_ratios, rmse_values, marker='o')\n",
    "\n",
    "    # Fill the area under the curve\n",
    "    plt.fill_between(test_ratios, rmse_values, alpha=0.3)\n",
    "    \n",
    "    plt.xlabel('Testing:Training Ratio', fontsize=15)\n",
    "    plt.ylabel('RMSE of Biomass (pgC/L)fn', fontsize=15)\n",
    "    plt.title(f\"{title_prefix} - RMSE of Biomass vs. Testing: Training Ratio\", fontsize=22)\n",
    "\n",
    "    plt.xlim(0, 1)  # Set the x-axis limits from 0 to 1\n",
    "    \n",
    "    plt.xticks([i/10 for i in range(11)])  # Set the x-axis tick locations at 0.1 increments\n",
    "    #inversing the x axis\n",
    "    plt.gca().invert_xaxis()\n",
    "\n",
    "    \n",
    "    plt.grid(True)  # Add a grid to the plot\n",
    "    \n",
    "    plt.tight_layout()  # Improves spacing between the plot elements\n",
    "    plt.show()\n",
    "    \n",
    "    return RMSEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a function to plot out-of-bag error (OOB) againts number of trees in random forest model\n",
    "\n",
    "This function tests different numbers of trees used in the random forest model and finds the OOB for each number of trees.  This is then called in each population-specific notebook to find the optimal number of trees for that population's model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def plot_oob_error_vs_num_trees(train_features, train_labels, title_prefix):\n",
    "    \"\"\"\n",
    "    Developes a plot of Out of Bag (oob) error vs the number of trees grown in a random forest model. There are\n",
    "        three labeled lines within the plot one representing.\n",
    "    \n",
    "    Max features represent the amount of all features (varaibles we are predicting on) used for each \n",
    "        tree in the random forest. n = all features.\n",
    "    \n",
    "    Warm start = true:reuse the solution of the previous call to fit and add more\n",
    "        estimators to the ensemble, otherwise, just fit a whole new forest.\n",
    "        \n",
    "    oob_score = True: Use out-of-bag samples to estimate the generalization score. By default, r2_score is used.\n",
    "        Provide a callable with signature.\n",
    "    \n",
    "    random state: controls random number generator that is used to shuffle/split the data. Ensures the same\n",
    "        randomization is used each time the code is ran.\n",
    "    \n",
    "    \"\"\"\n",
    "    RANDOM_STATE = 42\n",
    "\n",
    "    ensemble_clfs = [\n",
    "        (\n",
    "            \"max_features='sqrt(n)'\",\n",
    "            RandomForestRegressor(\n",
    "                warm_start=True,\n",
    "                max_features=\"sqrt\",\n",
    "                oob_score=True,\n",
    "                random_state=RANDOM_STATE,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"max_features='1/3 n'\",\n",
    "            RandomForestRegressor(\n",
    "                warm_start=True,\n",
    "                max_features=1/3,\n",
    "                oob_score=True,\n",
    "                random_state=RANDOM_STATE,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"max_features= n\",\n",
    "            RandomForestRegressor(\n",
    "                warm_start=True,\n",
    "                max_features=None,\n",
    "                oob_score=True,\n",
    "                random_state=RANDOM_STATE,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "    min_estimators = 15\n",
    "    max_estimators = 128\n",
    "\n",
    "    for label, clf in ensemble_clfs:\n",
    "        for i in range(min_estimators, max_estimators + 1, 5):\n",
    "            oob_errors = []\n",
    "            for fold_features, fold_labels in zip(train_features, train_labels):\n",
    "                clf.set_params(n_estimators=i)\n",
    "                clf.fit(fold_features, fold_labels)\n",
    "                oob_error = 1 - clf.oob_score_\n",
    "                oob_errors.append(oob_error)\n",
    "            avg_oob_error = np.mean(oob_errors)\n",
    "            error_rate[label].append((i, avg_oob_error))\n",
    "    for label, clf_err in error_rate.items():\n",
    "        xs, ys = zip(*clf_err)\n",
    "        plt.plot(xs, ys, label=label)\n",
    "\n",
    "    plt.xlim(min_estimators, max_estimators)\n",
    "    plt.xlabel(\"# of Trees\")\n",
    "    plt.ylabel(\"OOB error rate (1 - R^2)\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.suptitle(f\"{title_prefix} - Out-of-Bag Error Rate vs. Number of Trees in Random Forest Regression\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions to compare predicted biomass with actual data\n",
    "\n",
    "These functions give us a preliminary look at how well the model is predicting biomass.  These are called in each of the population specific notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_model_predictions():\n",
    "    \"\"\"\n",
    "    Creates two plots. First a Line density plot with the Root Mean Square Percentage Error (RMSPE) displayed \n",
    "    with two line density placments one for predicted and one for actual values. The second plot displayes a \n",
    "    scatter density plot of predicted vs true values with a linear regression line.\n",
    "    \"\"\"\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    import seaborn as sns\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    \n",
    "    # First subplot: Line Density Plot\n",
    "    ax1 = axes[0]\n",
    "    mae = mean_absolute_error(test_labels[ftu], predictions)\n",
    "    sns.histplot(x=test_labels[ftu], fill=True, color=\"blue\", label=\"True Values\", ax=ax1)\n",
    "    sns.histplot(x=predictions, fill=True, color=\"red\", label=\"Predictions\", ax=ax1)\n",
    "    ax1.text(0.05, 0.9, 'RMSPE = {:.2f}%'.format(percentage_RMSE), transform=ax1.transAxes, fontsize=20)\n",
    "    ax1.set_xlabel('Biomass (pgC per L)')\n",
    "    ax1.set_ylabel('Density')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "\n",
    "    # Second subplot: Scatter Plot with Linear Regression Line\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_xlabel('Actual Biomass (pgC per L)')\n",
    "    ax2.set_ylabel('Predicted Biomass (pgC per L)')\n",
    "    ax2.set_ylim(0, max(test_labels.max(), predictions.max())-5)\n",
    "    ax2.set_xlim(0, max(test_labels.max(), predictions.max())-5)\n",
    "    ax2.set_aspect('equal')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    \n",
    "    # PRO Model Predictions vs True Values\n",
    "    sns.kdeplot(x=test_labels[ftu], y=predictions, shade=True, cmap=\"Reds\", ax=ax2)\n",
    "    ax2.set_aspect('equal')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Add linear regression line\n",
    "    x = test_labels[ftu]\n",
    "    y = predictions\n",
    "    slope, intercept = np.polyfit(x, y, 1)\n",
    "    ax2.plot(x, slope*x + intercept, color='blue', label='Linear Regression Line')\n",
    "    ax2.legend(loc='upper left')  # Add legend to the upper left corner of the plot\n",
    "\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the plot\n",
    "    \n",
    "    return fig, axes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_model_predictions_density():\n",
    "    \"\"\"\n",
    "    Displayes a  scatter density plot of predicted vs true values with a linear regression line in addition\n",
    "    to a one-to-one line that displays a proportionate relationship\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    import seaborn as sns\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "\n",
    "\n",
    "    # Scatter Plot with Linear Regression Line\n",
    "    ax.set_xlabel('Actual Biomass (pgC per L)', fontsize=24)\n",
    "    ax.set_ylabel('Predicted Biomass (pgC per L)', fontsize=24)\n",
    "    ax.set_ylim(0, max(test_labels.max(), predictions.max())-5)\n",
    "    ax.set_xlim(0, max(test_labels.max(), predictions.max())-5)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True)\n",
    "    ax.text(0.05, 0.9, 'RMSPE = {:.2f} %'.format(percentage_RMSE), transform=ax.transAxes, fontsize=20)\n",
    "    \n",
    "    \n",
    "    # PRO Model Predictions vs True Values\n",
    "    sns.kdeplot(x=test_labels[ftu], y=predictions, shade=True, cmap=\"Reds\", ax=ax)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Add linear regression line\n",
    "    x = test_labels[ftu]\n",
    "    y = predictions\n",
    "    slope, intercept = np.polyfit(x, y, 1)\n",
    "    ax.plot(x, slope*x + intercept, color='blue', label='Linear Regression')\n",
    "    \n",
    "    # Add black dashed one-to-one line\n",
    "    max_val = max(test_labels.max(), predictions.max())\n",
    "    ax.plot([0, max_val], [0, max_val], linestyle='--', color='black', label='One-to-One')\n",
    "\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the plot\n",
    "    \n",
    "    return fig, ax\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
