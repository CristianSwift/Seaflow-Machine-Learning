{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9cfc381",
   "metadata": {},
   "source": [
    "# Here we make a Random Forest Model For Prochlorococcus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a working directory\n",
    "#!pip install GitPython\n",
    "import git\n",
    "import os\n",
    "\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "\n",
    "\n",
    "os.chdir(repo.working_tree_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38fc41",
   "metadata": {},
   "source": [
    "###  Running the model preparation notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running model preperation notebook that has a function we need to call\n",
    "%run 'Python/04_Populations-model-fitting/01_model-preparation.ipynb'\n",
    "#%run '/Users/cristianswift/Desktop/armbrust-lab/Seaflow-Machine-Learning/python/04_Populations-model-fitting/01_model-preparation.ipynb'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading packages for random forest modeling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import forestci as fci\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484671b",
   "metadata": {},
   "source": [
    "### First we are making a graph to determine the best testing to training ratio \n",
    "\n",
    "This is using a function that we defined in notebook 01_model-preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea97d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#using a function defined in the model preparation notebook\n",
    "RMSEs = testing_training_ratio(features = features_pro, labels = labels_pro,\n",
    "                               feature_list=feature_list_pro, title_prefix=\"Prochlorococcus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_RMSEs = testing_training_ratio_random(features = features_pro, labels = labels_pro,\n",
    "                                        feature_list=feature_list_pro, title_prefix=\"Prochlorococcus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b272aab",
   "metadata": {},
   "source": [
    "## RF Regressor for Prochlorococcus\n",
    "\n",
    "Here we are first calling a function defined in the model preparation notebook to find the optimal number of decision trees for out model, and then we are assembling a random forest regressor model for the prochlorococcus population.  This is then saved in a joblib file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of splits for k-fold cross-validation\n",
    "n_splits = 8\n",
    "kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "# Initialize lists to hold training and testing data\n",
    "train_features = []\n",
    "test_features = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "# Split the data into training and testing sets for each fold\n",
    "for train_index, test_index in kf.split(features_pro):\n",
    "    train_feat, test_feat = features_pro[train_index], features_pro[test_index]\n",
    "    train_lab, test_lab = labels_pro[train_index], labels_pro[test_index]\n",
    "    \n",
    "    # Append the training and testing data for this fold to the lists\n",
    "    train_features.append(train_feat)\n",
    "    test_features.append(test_feat)\n",
    "    train_labels.append(train_lab)\n",
    "    test_labels.append(test_lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81f2147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_oob_error_vs_num_trees(train_features, train_labels, title_prefix=\"Prochlorococcus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f83306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the shape of the features and labels to see if they match up\n",
    "import numpy\n",
    "lengths = [len(sublist) for sublist in train_features]\n",
    "print(set(lengths))\n",
    "print(type(train_features))\n",
    "print(type(train_labels))\n",
    "print(features_pro)\n",
    "train_features = numpy.array(train_features)\n",
    "train_labels = numpy.array(train_labels)\n",
    "test_features = numpy.array(test_features)\n",
    "test_labels = numpy.array(test_labels)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using a regressor RF model because we are predicting on continous values\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize a list to hold the models for each fold\n",
    "models = []\n",
    "\n",
    "# Loop over the folds\n",
    "for i in range(train_features.shape[0]):\n",
    "    # Instantiate model with 100 decision trees\n",
    "    rf = RandomForestRegressor(n_estimators = 120, max_depth=16, max_features='sqrt', random_state = 42)\n",
    "    \n",
    "    # Use the Training data to build the model\n",
    "    rf.fit(train_features[i], train_labels[i])\n",
    "    \n",
    "    # Append the model to the list\n",
    "    models.append(rf)\n",
    "\n",
    "# Save the models\n",
    "for i, model in enumerate(models):\n",
    "    joblib.dump(model, f\"RF_models/pro_random_forest_fold_{i}.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# # Define the hyperparameters grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [20, 50, 100, 200],\n",
    "#     'max_depth': [None, 8, 16, 32, 64],\n",
    "#     'max_features': ['sqrt', 'log2', None]\n",
    "# }\n",
    "\n",
    "# # Initialize the model\n",
    "# rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# numK=[2,4,6,8,10,12,14,16]\n",
    "\n",
    "# for i in numK:\n",
    "#     # Initialize the grid search\n",
    "#     grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=i, scoring='r2', error_score='raise', verbose=3)\n",
    "\n",
    "#     # Fit the grid search to the data\n",
    "#     grid_search.fit(features_pro, labels_pro)\n",
    "\n",
    "#     # Get the best hyperparameters\n",
    "#     best_params = grid_search.best_params_\n",
    "\n",
    "#     print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import forestci as fci\n",
    "\n",
    "# Initialize lists to hold predictions and errors\n",
    "predictions = []\n",
    "maes = []\n",
    "rmses = []\n",
    "confidence = []\n",
    "# Loop over the folds\n",
    "for i in range(test_features.shape[0]):\n",
    "    # Load the model for this fold\n",
    "    rf = joblib.load(f\"RF_models/pro_random_forest_fold_{i}.joblib\")\n",
    "    \n",
    "    # Use the model to predict on the test data for this fold\n",
    "    preds = rf.predict(test_features[i])\n",
    "    \n",
    "    # Calculate the errors\n",
    "    mae = mean_absolute_error(test_labels[i], preds)\n",
    "    RMSE = mean_squared_error(test_labels[i], preds, squared=False)\n",
    "\n",
    "    \n",
    "    confs = fci.random_forest_error(rf, train_features[i], test_features[i])\n",
    "    \n",
    "\n",
    "    # Append the predictions and errors to the lists\n",
    "    predictions.append(preds)\n",
    "    maes.append(mae)\n",
    "    rmses.append(RMSE)\n",
    "    confidence.append(confs)\n",
    "    # Save the predictions for each fold\n",
    "    data = {'predictions': preds,\n",
    "        'reals' : test_labels[i]}\n",
    "    \n",
    "    for key, value in data.items():\n",
    "        print(f\"Number of elements in {key}: {np.size(value)}\")\n",
    "    \n",
    "    actual = pd.DataFrame(data)\n",
    "    actual.to_csv(f'actual_pro{i}.csv', index=False)\n",
    "\n",
    "\n",
    "# Convert lists of arrays to 2D arrays\n",
    "\n",
    "predictions = np.concatenate(predictions)\n",
    "confidence = np.concatenate(confidence)\n",
    "maes = np.array(maes)\n",
    "rmses = np.array(rmses)\n",
    "rmse = np.sqrt(np.mean(rmses**2))\n",
    "\n",
    "# Print the mean absolute errors and root mean square errors\n",
    "print('Mean Absolute Errors:', maes)\n",
    "print('Root Mean Squared Errors:', rmses)\n",
    "print('Mean RMSE:', rmse)\n",
    "print(len(predictions))\n",
    "print(len(confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "covari_path = 'data/modified/RF_ready_covari.csv'\n",
    "#using pandas to read in as a df\n",
    "covari = (pd.read_csv(covari_path,parse_dates=[0]))\n",
    "#taking a peak at the data\n",
    "covari.head(3)\n",
    "covari_pro = covari[covari['population'] == 'Prochlorococcus']\n",
    "covari_pro.reset_index(drop=True, inplace=True)\n",
    "covari_pro.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = covari_pro.reset_index()\n",
    "\n",
    "predicted_df = pd.DataFrame(predictions, columns=['prediction'])\n",
    "#adding header to predictions\n",
    "head = 'predicted'\n",
    "header = pd.DataFrame([head], index=[0])\n",
    "# Concatenate the new row and the existing DataFrame\n",
    "predicted_df = pd.concat([header, predicted_df]).reset_index()\n",
    "\n",
    "predicted_df['index'] = original_df.index\n",
    "\n",
    "\n",
    "\n",
    "conf_df = pd.DataFrame(confidence, columns=['confidence'])\n",
    "#adding header to predictions\n",
    "head = 'confidence'\n",
    "header = pd.DataFrame([head], index=[0])\n",
    "# Concatenate the new row and the existing DataFrame\n",
    "conf_df = pd.concat([header, conf_df]).reset_index()\n",
    "\n",
    "conf_df['index'] = original_df.index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Merge the two dataframes on the index\n",
    "merged_df = pd.merge(original_df, predicted_df, on='index')\n",
    "merged_df = pd.merge(merged_df, conf_df, on='index')\n",
    "# Set the index back to the original column\n",
    "merged_df = merged_df.set_index('index')\n",
    "merged_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "#suppress future warnings (since we are version controlled and don't need to see them)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "#plot for each fold reals vs preds on that fold's test data\n",
    "for f in fold:\n",
    "    actual = pd.read_csv(f'actual_pro{f}.csv')\n",
    "    # #Create scatter reals v preds\n",
    "    #sns.scatterplot(x='reals', y='predictions', data=actual)\n",
    "    #create density plot\n",
    "    sns.kdeplot(x='reals', y='predictions', data=actual, fill=True, cmap=\"Reds\", thresh=0.05)\n",
    "    # Add a reference line from (0,0) to (1,1)\n",
    "    plt.plot([0, 1], [0, 1], transform=plt.gca().transAxes, ls='--', c='black')\n",
    "\n",
    "    # #linear regression line\n",
    "    # x = data['reals']\n",
    "    # y = data['predictions']\n",
    "    # slope, intercept = np.polyfit(x, y, 1)\n",
    "    # plt.plot(x, slope*x + intercept, color='blue', label='Linear Regression')\n",
    "    \n",
    "    plt.title(f'Prochlorococcus Fold {f+1}')\n",
    "    plt.savefig(f'pro_fold{f+1}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confidence[:3])\n",
    "print(predictions[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def create_fold_predictions_time(pop_df, title_prefix='Prochlorococcus'):\n",
    "    \"\"\"\n",
    "    Makes an actual vs prediction plot for each fold by time\n",
    "    \"\"\"\n",
    "    unique_cruises = merged_df['cruisename'].unique()\n",
    "\n",
    "    # Create a subplot grid\n",
    "    num_cruises = len(unique_cruises)\n",
    "    rows = int(num_cruises / 2) if num_cruises % 2 == 0 else int(num_cruises / 2) + 1\n",
    "    fig = make_subplots(rows=rows, cols=2, subplot_titles=unique_cruises)\n",
    "\n",
    "    # Define colors for 'actual' and 'prediction' traces\n",
    "    actual_color = 'blue'\n",
    "    prediction_color = 'red'\n",
    "\n",
    "    # Define colors for 'each fold\n",
    "    colors = ['blue', 'green'] \n",
    "\n",
    "    # Initialize a counter for the color of each point\n",
    "    point_counter = 0  \n",
    "\n",
    "    #determine y range\n",
    "    y_range = [merged_df[['biomass', 'prediction']].min().min() - 1, merged_df[['biomass', 'prediction']].max().max()+1]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Iterate over each unique cruise and add a subplot\n",
    "    for i, cruise in enumerate(unique_cruises):\n",
    "        # Filter dataframe for the current cruise\n",
    "        cruise_df = merged_df[merged_df['cruisename'] == cruise]\n",
    "\n",
    "        # Create a color list for the current cruise\n",
    "        cruise_color_list = [colors[(point_counter + j) // 299 % len(colors)] for j in range(len(cruise_df))]\n",
    "\n",
    "        # Update the point counter\n",
    "        point_counter += len(cruise_df)\n",
    "        print(len(cruise_df))\n",
    "        print(point_counter)\n",
    "        # Add the scatter plots for 'actual' and 'prediction' to the subplot\n",
    "        row = int(i / 2) + 1\n",
    "        col = i % 2 + 1\n",
    "        fig.add_trace(go.Scatter(x=cruise_df['time'], y=cruise_df['biomass'], mode='markers', name='Actual',\n",
    "                                marker=dict(color=cruise_color_list)),\n",
    "                    row=row, col=col)\n",
    "        fig.add_trace(go.Scatter(x=cruise_df['time'], y=cruise_df['prediction'], mode='lines', name='Prediction',\n",
    "                                line=dict(color=prediction_color)),\n",
    "                    row=row, col=col)\n",
    "        fig.update_xaxes(title_text='Time', row=row, col=col)\n",
    "        fig.update_yaxes(title_text='Value', row=row, col=col)\n",
    "        #set y range\n",
    "        fig.update_yaxes(range=y_range, row=row, col=col)\n",
    "        # Add confidence interval\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=cruise_df['time'],\n",
    "            y=cruise_df['prediction'] + cruise_df['confidence'],\n",
    "            mode='lines',\n",
    "            marker=dict(color=\"#444\"),\n",
    "            line=dict(width=0),\n",
    "            showlegend=False),\n",
    "            row=row, col=col)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=cruise_df['time'],\n",
    "            y=cruise_df['prediction'] - cruise_df['confidence'],\n",
    "            marker=dict(color=\"#444\"),\n",
    "            line=dict(width=0),\n",
    "            mode='lines',\n",
    "            fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "            fill='tonexty',\n",
    "            showlegend=False),\n",
    "            row=row, col=col)\n",
    "\n",
    "    # Update the layout and display the figure\n",
    "    fig.update_layout(height=600 * rows, width=1200, title_text='Actual and Prediction for Each Cruise')\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fold_predictions_time(merged_df, title_prefix='Prochlorococcus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for f in fold:\n",
    "    pd.read_csv(f'actual_pro{f}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79395f57",
   "metadata": {},
   "source": [
    "## Predicting and Testing for Prochlorococus\n",
    "\n",
    "Now that we have a model, it's time to test it.  These following functions compare the predictions from out random forest model to actual data, and then use this comparison to give us feature importance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ce11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in fold:\n",
    "#     # Convert test_features to a DataFrame\n",
    "#     test_features_df = pd.DataFrame(test_features[f], columns=feature_list_pro)\n",
    "\n",
    "#     # Use the forest's predict method on the test data\n",
    "#     predictions = rf.predict(test_features[f])\n",
    "\n",
    "#     # Create a new Series with predicted values and index from test_features_df\n",
    "#     predic_biomass = pd.Series(predictions, index=test_features_df.index)\n",
    "\n",
    "#     # Assign the new Series to the DataFrame using .loc\n",
    "#     test_features_df.loc[:, 'Prediction'] = predic_biomass\n",
    "\n",
    "#     # Calculate the absolute errors\n",
    "#     errors = abs(predictions - test_labels)\n",
    "\n",
    "#     # Print out the mean absolute error (mae)\n",
    "#     from sklearn.metrics import mean_absolute_error\n",
    "#     mae = mean_absolute_error(test_labels[f], predictions)\n",
    "#     print('Mean Absolute Error:', round(mae, 2), 'pgC per L.')\n",
    "\n",
    "#     # Finding the root mean square error (RMSE)\n",
    "#     from sklearn.metrics import mean_squared_error\n",
    "#     # RMSE give realtively high weight to large errors \n",
    "#     RMSE = mean_squared_error(test_labels[f], predictions, squared=False) #setting squared=False gives us RMSE not MSE\n",
    "\n",
    "#     # Calculate the percentage of RMSE\n",
    "#     range_target = test_labels.max() - test_labels.min()\n",
    "#     percentage_RMSE = (RMSE / range_target) * 100\n",
    "\n",
    "#     print('Root Mean Squared Error:', round(RMSE, 2), 'pgC per L.')\n",
    "#     print('Percentage of RMSE:', round(percentage_RMSE, 2), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c32507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list_pro, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(rf.feature_importances_, index=feature_list_pro).sort_values(by=0, ascending=False)\n",
    "\n",
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "# Make a bar chart\n",
    "plt.bar(x=feature_importance.index,height=feature_importance[0], orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(feature_importance.index, rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.title('Variable Importances for Pro RF');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b4fb96",
   "metadata": {},
   "source": [
    "### Permutation importance as a method of assessing feature importance\n",
    "\n",
    "Permutation importance tests feature importance by permuting branches on RF trees to asses the impact of changing specific variables on the prediction.  This is an additional way to validate our feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(\n",
    "    rf, test_features, test_labels, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "\n",
    "\n",
    "forest_importances = pd.DataFrame(result.importances_mean, index=feature_list_pro).sort_values(by=0, ascending=False)\n",
    "forest_importances.to_csv('data/modified/pro_permutation_importance.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8725195",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation on full model\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd08cb",
   "metadata": {},
   "source": [
    "### Comparing predicted biomass vs actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ae94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_model_predictions()\n",
    "\n",
    "axs[1].set_title('Prochlorococcus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf152f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Call the function and store the figure and axes objects\n",
    "# Assuming plot_model_predictions_density() generates a plot and returns the figure and axes objects\n",
    "fig, ax = plot_model_predictions_density()\n",
    "\n",
    "# Set the title for the single subplot\n",
    "ax.set_xlim(0, 15)  # Example x-axis limits\n",
    "ax.set_ylim(0, 15)  # Example y-axis limits\n",
    "    \n",
    "ax.set_title('Prochlorococcus', fontsize=20)\n",
    "\n",
    "\n",
    "\n",
    "# Display Legend\n",
    "ax.legend(loc=\"lower right\", )\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)  # Adjust the fontsize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the plot with the updated title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb0260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(test_labels[ftu], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a951aa8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
