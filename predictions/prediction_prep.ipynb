{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a working directory\n",
    "#!pip install GitPython\n",
    "import git\n",
    "import os\n",
    "\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "\n",
    "\n",
    "os.chdir(repo.working_tree_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_single_population(covari_population):\n",
    "    \"\"\"\n",
    "    Takes the covari dataframe, and whichever of the four populations and returns a dataframe that\n",
    "    only includes the selected population's rows, a list of labels (biomass values associated with the dataframe)\n",
    "    and a list of all of the features.\n",
    "    \"\"\"\n",
    "    # Selecting the population based on the provided name\n",
    "    pop_df = covari_population\n",
    "    \n",
    "    # pop_df.drop(columns='hours_since_sunrise', inplace=True)\n",
    "\n",
    "    # Creating the labels and features for the population\n",
    "    labels = np.array(pop_df.biomass, copy=True)\n",
    "    labels = np.delete(labels, 0, 0)\n",
    "    features = pop_df.drop(['time', 'biomass', 'lat', 'lon', 'cruise'], axis=1, inplace=False)\n",
    "    # Saving feature names for later use\n",
    "    feature_list = list(features.columns)\n",
    "    features = features.to_numpy()\n",
    "    features = np.delete(features, 0, 0)\n",
    "    return pop_df, labels, features, feature_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_global(covari_population):\n",
    "    \"\"\"\n",
    "    Takes the covari dataframe, and whichever of the four populations and returns a dataframe that\n",
    "    only includes the selected population's rows, a list of labels (biomass values associated with the dataframe)\n",
    "    and a list of all of the features.\n",
    "    \"\"\"\n",
    "    # Selecting the population based on the provided name\n",
    "    pop_df = covari_population.copy()\n",
    "    pop_df['biomass'] = 0.0\n",
    "    if 'time' not in pop_df.columns:\n",
    "        pop_df['time'] = 0.0\n",
    "    # pop_df.drop(columns='hours_since_sunrise', inplace=True)\n",
    "\n",
    "    # Creating the labels and features for the population\n",
    "    labels = np.array(pop_df.biomass, copy=True)\n",
    "    labels = np.delete(labels, 0, 0)\n",
    "    features = pop_df.drop(['time', 'lat', 'lon', 'biomass'], axis=1, inplace=False)\n",
    "    # Saving feature names for later use\n",
    "    feature_list = list(features.columns)\n",
    "    features = features.to_numpy()\n",
    "    features = np.delete(features, 0, 0)\n",
    "    return pop_df, labels, features, feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cruise</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>biomass_pro</th>\n",
       "      <th>biomass_syn</th>\n",
       "      <th>biomass_pico</th>\n",
       "      <th>biomass_croco</th>\n",
       "      <th>sss</th>\n",
       "      <th>sst</th>\n",
       "      <th>Fe</th>\n",
       "      <th>O2</th>\n",
       "      <th>NO3</th>\n",
       "      <th>PO4</th>\n",
       "      <th>Si</th>\n",
       "      <th>ALK</th>\n",
       "      <th>hours_since_sunrise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-22 22:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.343400</td>\n",
       "      <td>-158.273700</td>\n",
       "      <td>4.024661</td>\n",
       "      <td>0.337763</td>\n",
       "      <td>0.555395</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>34.571716</td>\n",
       "      <td>25.653118</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>1952.6418</td>\n",
       "      <td>6.129444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-22 23:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.343533</td>\n",
       "      <td>-158.273744</td>\n",
       "      <td>4.167834</td>\n",
       "      <td>0.413687</td>\n",
       "      <td>0.720884</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>34.571716</td>\n",
       "      <td>25.653118</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>1952.6418</td>\n",
       "      <td>7.129444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-23 00:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.346175</td>\n",
       "      <td>-158.274150</td>\n",
       "      <td>4.654360</td>\n",
       "      <td>0.654208</td>\n",
       "      <td>0.635654</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>34.609317</td>\n",
       "      <td>25.646243</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>1952.6418</td>\n",
       "      <td>8.129722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  cruise        lat         lon  biomass_pro  \\\n",
       "0 2015-05-22 22:00:00  KM1508  21.343400 -158.273700     4.024661   \n",
       "1 2015-05-22 23:00:00  KM1508  21.343533 -158.273744     4.167834   \n",
       "2 2015-05-23 00:00:00  KM1508  21.346175 -158.274150     4.654360   \n",
       "\n",
       "   biomass_syn  biomass_pico  biomass_croco        sss        sst        Fe  \\\n",
       "0     0.337763      0.555395       0.009181  34.571716  25.653118  0.000088   \n",
       "1     0.413687      0.720884       0.013144  34.571716  25.653118  0.000088   \n",
       "2     0.654208      0.635654       0.008443  34.609317  25.646243  0.000088   \n",
       "\n",
       "           O2           NO3       PO4        Si        ALK  \\\n",
       "0  216.794167  4.269278e-07  0.345151  9.464704  1952.6418   \n",
       "1  216.794167  4.269278e-07  0.345151  9.464704  1952.6418   \n",
       "2  216.794167  4.269278e-07  0.345151  9.464704  1952.6418   \n",
       "\n",
       "   hours_since_sunrise  \n",
       "0             6.129444  \n",
       "1             7.129444  \n",
       "2             8.129722  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "covari_path = 'data_ingest/data/modified/RF_ready_covari.csv'\n",
    "#using pandas to read in as a df\n",
    "covari = (pd.read_csv(covari_path,parse_dates=[0]))\n",
    "#taking a peak at the data\n",
    "covari.drop(columns=['ugos', 'vgos'], inplace=True)\n",
    "covari.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "covari_pro = covari.drop(columns=['biomass_pico','biomass_croco','biomass_syn'])\n",
    "covari_syn = covari.drop(columns=['biomass_pico','biomass_croco','biomass_pro'])\n",
    "covari_pico = covari.drop(columns=['biomass_syn','biomass_croco','biomass_pro'])\n",
    "covari_croco = covari.drop(columns=['biomass_pico','biomass_syn','biomass_pro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_dfer(covari_pop, pop_name):\n",
    "    \"\"\"\n",
    "    This function removes population names from the columns of each df\n",
    "    \"\"\"\n",
    "    df = covari_pop\n",
    "    pop_name = pop_name\n",
    "    df.rename(columns=lambda x: x.replace('_'+pop_name, ''), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_dfer(covari_syn, 'syn')\n",
    "population_dfer(covari_pro, 'pro')\n",
    "population_dfer(covari_pico, 'pico')\n",
    "population_dfer(covari_croco, 'croco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_df, labels_pro, features_pro, feature_list_pro = preprocess_single_population(covari_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of splits for k-fold cross-validation\n",
    "n_splits = 8\n",
    "kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "# Initialize lists to hold training and testing data\n",
    "train_features = []\n",
    "test_features = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "# Split the data into training and testing sets for each fold\n",
    "for train_index, test_index in kf.split(features_pro):\n",
    "    train_feat, test_feat = features_pro[train_index], features_pro[test_index]\n",
    "    train_lab, test_lab = labels_pro[train_index], labels_pro[test_index]\n",
    "    \n",
    "    # Append the training and testing data for this fold to the lists\n",
    "    train_features.append(train_feat)\n",
    "    test_features.append(test_feat)\n",
    "    train_labels.append(train_lab)\n",
    "    test_labels.append(test_lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = [0,1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(data):\n",
    "    # Find the length of the shortest sublist\n",
    "    min_len = min(len(sublist) for sublist in data)\n",
    "\n",
    "    # Remove data points from each sublist until they are all the same length\n",
    "    data_truncated = [sublist[:min_len] for sublist in data]\n",
    "\n",
    "    return data_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = equalize(train_features)\n",
    "test_features = equalize(test_features)\n",
    "train_labels = equalize(train_labels)\n",
    "test_labels = equalize(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "lengths = [len(sublist) for sublist in train_features]\n",
    "\n",
    "train_features = numpy.array(train_features)\n",
    "train_labels = numpy.array(train_labels)\n",
    "test_features = numpy.array(test_features)\n",
    "test_labels = numpy.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using a regressor RF model because we are predicting on continous values\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "# Initialize a list to hold the models for each fold\n",
    "models = []\n",
    "\n",
    "\n",
    "\n",
    "# Loop over the folds\n",
    "for i in range(train_features.shape[0]):\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators = 120, max_features='sqrt', max_depth = 12, random_state = 42)\n",
    "    \n",
    "   \n",
    "    rf.fit(train_features[i], train_labels[i])\n",
    "    \n",
    "    \n",
    "    models.append(rf)\n",
    "\n",
    "# Save the models\n",
    "for i, model in enumerate(models):\n",
    "    joblib.dump(model, f\"RF_models/predictions/pro_random_forest_fold_{i}.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(features_pro, labels_pro, splits):\n",
    "    # initialize kfold\n",
    "    n_splits = splits\n",
    "    kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "    # Initialize lists to hold training and testing data\n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    # Split the data into training and testing sets for each fold\n",
    "    for train_index, test_index in kf.split(features_pro):\n",
    "        train_feat, test_feat = features_pro[train_index], features_pro[test_index]\n",
    "        train_lab, test_lab = labels_pro[train_index], labels_pro[test_index]\n",
    "        \n",
    "        # Append the training and testing data for this fold to the lists\n",
    "        train_features.append(train_feat)\n",
    "        test_features.append(test_feat)\n",
    "        train_labels.append(train_lab)\n",
    "        test_labels.append(test_lab)\n",
    "    return train_features, test_features, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "def model_training(train_features, train_labels, test_features, test_labels, hyperparameters):\n",
    "    '''\n",
    "    this function trains a random forest regressor model for each fold and saves the model\n",
    "    '''\n",
    "    # make sure features and labels are the same length\n",
    "    train_features = equalize(train_features)\n",
    "    test_features = equalize(test_features)\n",
    "    train_labels = equalize(train_labels)\n",
    "    test_labels = equalize(test_labels)\n",
    "\n",
    "\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_features = np.array(test_features)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    \n",
    "    models = []\n",
    "    n_estimators = hyperparameters['n_estimators']\n",
    "    max_depth = hyperparameters['max_depth']\n",
    "    max_features = hyperparameters['max_features']\n",
    "    # Loop over the folds\n",
    "    for i in range(train_features.shape[0]):\n",
    "        \n",
    "        rf = RandomForestRegressor(n_estimators = n_estimators, max_features=max_features, max_depth = max_depth, random_state = 33)\n",
    "        \n",
    "    \n",
    "        rf.fit(train_features[i], train_labels[i])\n",
    "        \n",
    "        \n",
    "        models.append(rf)\n",
    "\n",
    "    # Save the models\n",
    "    for i, model in enumerate(models):\n",
    "        joblib.dump(model, f\"RF_models/predictions/new_features/pro_random_forest_fold_{i}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(covari_pro):\n",
    "    covari_pro = covari_pro.drop(columns=['O2', 'NO3', 'PO4', 'Si'])\n",
    "    pro_df, labels_pro, features_pro, feature_list_pro = preprocess_single_population(covari_pro)\n",
    "    splits = 8\n",
    "    train_features, test_features, train_labels, test_labels = k_fold(features_pro, labels_pro, splits)\n",
    "    hyperparameters = {\n",
    "    'n_estimators': 120,\n",
    "    'max_features': 'sqrt',\n",
    "    'max_depth': 10,\n",
    "    'random_state': 33\n",
    "    }   \n",
    "    model_training(train_features, train_labels, test_features, test_labels, hyperparameters)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def predict_global(features, new):\n",
    "    '''\n",
    "    This uses our 8 trained models (one per fold) to predict on the global features\n",
    "    '''\n",
    "    predictions = []\n",
    "    for f in fold:\n",
    "        if new:\n",
    "            rf = joblib.load(f\"RF_models/predictions/new_features/pro_random_forest_fold_{f}.joblib\")\n",
    "        else:\n",
    "            rf = joblib.load(f\"RF_models/predictions/pro_random_forest_fold_{f}.joblib\")\n",
    "        \n",
    "        # Use the model to predict on the test data for this fold\n",
    "        preds = rf.predict(features)\n",
    "        predictions.append(preds)\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_preparation(global_df, predictions):\n",
    "    '''\n",
    "    This function takes the predictions from the predict_global function and the global_df and returns global_df with the mean\n",
    "    and relative standard deviation of the predictions\n",
    "    '''\n",
    "    predictions.loc[-1] = [0,0,0,0,0,0,0,0]  \n",
    "    predictions.index = predictions.index + 1  \n",
    "    predictions = predictions.sort_index()\n",
    "    predictions['mean'] = predictions.mean(axis=1)\n",
    "    def pred_conf(preds):\n",
    "        preds['conf'] = preds.std(axis=1)\n",
    "        return preds['conf']\n",
    "\n",
    "    predictions['conf'] = pred_conf(predictions[[0, 1, 2, 3, 4, 5, 6, 7]])\n",
    "    global_df['biomass'] = predictions['mean']\n",
    "\n",
    "    \n",
    "    global_df['std'] = predictions['conf']\n",
    "    global_df['relative_std'] = (predictions['conf'] / predictions['mean'] * 100)\n",
    "    return global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_monthly(month_df, predictions):\n",
    "    '''\n",
    "    This function takes the predictions from the predict_global function and the global_df and returns global_df with the mean\n",
    "    and relative standard deviation of the predictions\n",
    "    '''\n",
    "    predictions.loc[-1] = [0,0,0,0,0,0,0,0]  \n",
    "    predictions.index = predictions.index + 1  \n",
    "    predictions = predictions.sort_index()     \n",
    "    predictions['mean'] = predictions.mean(axis=1)\n",
    "    def pred_conf(preds):\n",
    "        preds['conf'] = preds.std(axis=1)\n",
    "        return preds['conf']\n",
    "    predictions.reset_index(inplace=True)\n",
    "    month_df.reset_index(inplace=True)\n",
    "    predictions['conf'] = pred_conf(predictions[[0, 1, 2, 3, 4, 5, 6, 7]])\n",
    "    month_df['biomass'] = predictions['mean']\n",
    "\n",
    "    month_df['std'] = predictions['conf']\n",
    "    month_df['relative_std'] = (predictions['conf'] / predictions['mean'] * 100)\n",
    "    return month_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_yearly(month, m):\n",
    "    '''\n",
    "    This function takes the yearly dataframe and returns the dataframe with the mean and relative standard deviation of the predictions\n",
    "    '''\n",
    "    \n",
    "    month.drop(columns=['month'], inplace=True)\n",
    "\n",
    "    month_pop_df, labels_month, features_month, feature_list_month = preprocess_global(month)\n",
    "    predictions_m = predict_global(features_month, False)\n",
    "    \n",
    "    preds_month = pd.DataFrame(predictions_m).T\n",
    "    \n",
    "    month_pred = predictions_monthly(month, preds_month)\n",
    "    \n",
    "    month_pred['month'] = m\n",
    "    return month_pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_yearly(yearly):\n",
    "    \n",
    "    jan = yearly[yearly['month'] == 1]\n",
    "    feb = yearly[yearly['month'] == 2]\n",
    "    mar = yearly[yearly['month'] == 3]\n",
    "    apr = yearly[yearly['month'] == 4]\n",
    "    may = yearly[yearly['month'] == 5]\n",
    "    jun = yearly[yearly['month'] == 6]\n",
    "    jul = yearly[yearly['month'] == 7]\n",
    "    aug = yearly[yearly['month'] == 8]\n",
    "    sep = yearly[yearly['month'] == 9]\n",
    "    oct = yearly[yearly['month'] == 10]\n",
    "    nov = yearly[yearly['month'] == 11]\n",
    "    dec = yearly[yearly['month'] == 12]\n",
    "    month_dfs = [jan, feb, mar, apr, may, jun, jul, aug, sep, oct, nov, dec]\n",
    "    for i, df in enumerate(month_dfs):\n",
    "        df = predict_yearly(df, i+1)\n",
    "    predicted = pd.concat(month_dfs, axis=0)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
