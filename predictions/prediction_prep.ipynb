{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a working directory\n",
    "#!pip install GitPython\n",
    "import git\n",
    "import os\n",
    "\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "\n",
    "\n",
    "os.chdir(repo.working_tree_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_single_population(covari_population):\n",
    "    \"\"\"\n",
    "    Takes the covari dataframe, and whichever of the four populations and returns a dataframe that\n",
    "    only includes the selected population's rows, a list of labels (biomass values associated with the dataframe)\n",
    "    and a list of all of the features.\n",
    "    \"\"\"\n",
    "    # Selecting the population based on the provided name\n",
    "    pop_df = covari_population\n",
    "    \n",
    "    # pop_df.drop(columns='hours_since_sunrise', inplace=True)\n",
    "\n",
    "    # Creating the labels and features for the population\n",
    "    labels = np.array(pop_df.biomass, copy=True)\n",
    "    labels = np.delete(labels, 0, 0)\n",
    "    features = pop_df.drop(['time', 'biomass', 'lat', 'lon', 'cruise'], axis=1, inplace=False)\n",
    "    # Saving feature names for later use\n",
    "    feature_list = list(features.columns)\n",
    "    features = features.to_numpy()\n",
    "    features = np.delete(features, 0, 0)\n",
    "    return pop_df, labels, features, feature_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cruise</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>biomass_pro</th>\n",
       "      <th>biomass_syn</th>\n",
       "      <th>biomass_pico</th>\n",
       "      <th>biomass_croco</th>\n",
       "      <th>sss</th>\n",
       "      <th>sst</th>\n",
       "      <th>ugos</th>\n",
       "      <th>vgos</th>\n",
       "      <th>Fe</th>\n",
       "      <th>O2</th>\n",
       "      <th>NO3</th>\n",
       "      <th>PO4</th>\n",
       "      <th>Si</th>\n",
       "      <th>ALK</th>\n",
       "      <th>hours_since_sunrise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-22 22:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.343400</td>\n",
       "      <td>-158.273700</td>\n",
       "      <td>4.024661</td>\n",
       "      <td>0.337763</td>\n",
       "      <td>0.555395</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>34.571716</td>\n",
       "      <td>25.653118</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>-0.132531</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>1952.6418</td>\n",
       "      <td>6.129444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-22 23:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.343533</td>\n",
       "      <td>-158.273744</td>\n",
       "      <td>4.167834</td>\n",
       "      <td>0.413687</td>\n",
       "      <td>0.720884</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>34.571716</td>\n",
       "      <td>25.653118</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>-0.132531</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>1952.6418</td>\n",
       "      <td>7.129444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-23 00:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.346175</td>\n",
       "      <td>-158.274150</td>\n",
       "      <td>4.654360</td>\n",
       "      <td>0.654208</td>\n",
       "      <td>0.635654</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>34.609317</td>\n",
       "      <td>25.646243</td>\n",
       "      <td>-0.002256</td>\n",
       "      <td>-0.132022</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>1952.6418</td>\n",
       "      <td>8.129722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  cruise        lat         lon  biomass_pro  \\\n",
       "0 2015-05-22 22:00:00  KM1508  21.343400 -158.273700     4.024661   \n",
       "1 2015-05-22 23:00:00  KM1508  21.343533 -158.273744     4.167834   \n",
       "2 2015-05-23 00:00:00  KM1508  21.346175 -158.274150     4.654360   \n",
       "\n",
       "   biomass_syn  biomass_pico  biomass_croco        sss        sst      ugos  \\\n",
       "0     0.337763      0.555395       0.009181  34.571716  25.653118  0.005764   \n",
       "1     0.413687      0.720884       0.013144  34.571716  25.653118  0.005764   \n",
       "2     0.654208      0.635654       0.008443  34.609317  25.646243 -0.002256   \n",
       "\n",
       "       vgos        Fe          O2           NO3       PO4        Si  \\\n",
       "0 -0.132531  0.000088  216.794167  4.269278e-07  0.345151  9.464704   \n",
       "1 -0.132531  0.000088  216.794167  4.269278e-07  0.345151  9.464704   \n",
       "2 -0.132022  0.000088  216.794167  4.269278e-07  0.345151  9.464704   \n",
       "\n",
       "         ALK  hours_since_sunrise  \n",
       "0  1952.6418             6.129444  \n",
       "1  1952.6418             7.129444  \n",
       "2  1952.6418             8.129722  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "covari_path = 'data_ingest/data/modified/RF_ready_covari.csv'\n",
    "#using pandas to read in as a df\n",
    "covari = (pd.read_csv(covari_path,parse_dates=[0]))\n",
    "#taking a peak at the data\n",
    "covari.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "covari_pro = covari.drop(columns=['biomass_pico','biomass_croco','biomass_syn'])\n",
    "covari_syn = covari.drop(columns=['biomass_pico','biomass_croco','biomass_pro'])\n",
    "covari_pico = covari.drop(columns=['biomass_syn','biomass_croco','biomass_pro'])\n",
    "covari_croco = covari.drop(columns=['biomass_pico','biomass_syn','biomass_pro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_dfer(covari_pop, pop_name):\n",
    "    \"\"\"\n",
    "    This function removes population names from the columns of each df\n",
    "    \"\"\"\n",
    "    df = covari_pop\n",
    "    pop_name = pop_name\n",
    "    df.rename(columns=lambda x: x.replace('_'+pop_name, ''), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_dfer(covari_syn, 'syn')\n",
    "population_dfer(covari_pro, 'pro')\n",
    "population_dfer(covari_pico, 'pico')\n",
    "population_dfer(covari_croco, 'croco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_df, labels_pro, features_pro, feature_list_pro = preprocess_single_population(covari_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of splits for k-fold cross-validation\n",
    "n_splits = 8\n",
    "kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "# Initialize lists to hold training and testing data\n",
    "train_features = []\n",
    "test_features = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "# Split the data into training and testing sets for each fold\n",
    "for train_index, test_index in kf.split(features_pro):\n",
    "    train_feat, test_feat = features_pro[train_index], features_pro[test_index]\n",
    "    train_lab, test_lab = labels_pro[train_index], labels_pro[test_index]\n",
    "    \n",
    "    # Append the training and testing data for this fold to the lists\n",
    "    train_features.append(train_feat)\n",
    "    test_features.append(test_feat)\n",
    "    train_labels.append(train_lab)\n",
    "    test_labels.append(test_lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = [0,1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(data):\n",
    "    # Find the length of the shortest sublist\n",
    "    min_len = min(len(sublist) for sublist in data)\n",
    "\n",
    "    # Remove data points from each sublist until they are all the same length\n",
    "    data_truncated = [sublist[:min_len] for sublist in data]\n",
    "\n",
    "    return data_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = equalize(train_features)\n",
    "test_features = equalize(test_features)\n",
    "train_labels = equalize(train_labels)\n",
    "test_labels = equalize(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4094}\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "[[ 3.45717163e+01  2.56531183e+01  5.76444444e-03 ...  9.46470396e+00\n",
      "   1.95264180e+03  7.12944444e+00]\n",
      " [ 3.46093165e+01  2.56462433e+01 -2.25555556e-03 ...  9.46470396e+00\n",
      "   1.95264180e+03  8.12972222e+00]\n",
      " [ 3.46269515e+01  2.52466600e+01 -1.54770833e-01 ...  9.54816445e+00\n",
      "   1.95380275e+03  1.11466667e+01]\n",
      " ...\n",
      " [ 3.49623977e+01  2.48945779e+01 -4.86312500e-02 ...  5.54336847e-04\n",
      "   1.95756288e+03  1.05333333e+01]\n",
      " [ 3.49623977e+01  2.48945779e+01 -4.86312500e-02 ...  6.59941725e-04\n",
      "   1.95833642e+03  1.15255556e+01]\n",
      " [ 3.49402743e+01  2.50197858e+01 -5.21711111e-02 ...  6.59941725e-04\n",
      "   1.95833642e+03  1.25227778e+01]]\n",
      "Training Features Shape: (8, 4094, 11)\n",
      "Training Labels Shape: (8, 4094)\n",
      "Testing Features Shape: (8, 584, 11)\n",
      "Testing Labels Shape: (8, 584)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "lengths = [len(sublist) for sublist in train_features]\n",
    "print(set(lengths))\n",
    "print(type(train_features))\n",
    "print(type(train_labels))\n",
    "print(features_pro)\n",
    "train_features = numpy.array(train_features)\n",
    "train_labels = numpy.array(train_labels)\n",
    "test_features = numpy.array(test_features)\n",
    "test_labels = numpy.array(test_labels)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using a regressor RF model because we are predicting on continous values\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "# Initialize a list to hold the models for each fold\n",
    "models = []\n",
    "\n",
    "\n",
    "\n",
    "# Loop over the folds\n",
    "for i in range(train_features.shape[0]):\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators = 240, max_features='sqrt', max_depth = 10, random_state = 33)\n",
    "    \n",
    "   \n",
    "    rf.fit(train_features[i], train_labels[i])\n",
    "    \n",
    "    \n",
    "    models.append(rf)\n",
    "\n",
    "# Save the models\n",
    "for i, model in enumerate(models):\n",
    "    joblib.dump(model, f\"RF_models/pro_random_forest_fold_{i}.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(features_pro, labels_pro, splits):\n",
    "    # initialize kfold\n",
    "    n_splits = splits\n",
    "    kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "    # Initialize lists to hold training and testing data\n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    # Split the data into training and testing sets for each fold\n",
    "    for train_index, test_index in kf.split(features_pro):\n",
    "        train_feat, test_feat = features_pro[train_index], features_pro[test_index]\n",
    "        train_lab, test_lab = labels_pro[train_index], labels_pro[test_index]\n",
    "        \n",
    "        # Append the training and testing data for this fold to the lists\n",
    "        train_features.append(train_feat)\n",
    "        test_features.append(test_feat)\n",
    "        train_labels.append(train_lab)\n",
    "        test_labels.append(test_lab)\n",
    "    return train_features, test_features, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "def model_training(train_features, train_labels, test_features, test_labels, hyperparameters):\n",
    "    '''\n",
    "    this function trains a random forest regressor model for each fold and saves the model\n",
    "    '''\n",
    "    # make sure features and labels are the same length\n",
    "    train_features = equalize(train_features)\n",
    "    test_features = equalize(test_features)\n",
    "    train_labels = equalize(train_labels)\n",
    "    test_labels = equalize(test_labels)\n",
    "\n",
    "\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_features = np.array(test_features)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    \n",
    "    models = []\n",
    "    n_estimators = hyperparameters['n_estimators']\n",
    "    max_depth = hyperparameters['max_depth']\n",
    "    max_features = hyperparameters['max_features']\n",
    "    # Loop over the folds\n",
    "    for i in range(train_features.shape[0]):\n",
    "        \n",
    "        rf = RandomForestRegressor(n_estimators = n_estimators, max_features=max_features, max_depth = max_depth, random_state = 33)\n",
    "        \n",
    "    \n",
    "        rf.fit(train_features[i], train_labels[i])\n",
    "        \n",
    "        \n",
    "        models.append(rf)\n",
    "\n",
    "    # Save the models\n",
    "    for i, model in enumerate(models):\n",
    "        joblib.dump(model, f\"RF_models/pro_random_forest_fold_{i}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(covari_pro):\n",
    "    covari_pro = covari_pro.drop(columns=['ugos','vgos','O2', 'NO3', 'PO4', 'Si'])\n",
    "    pro_df, labels_pro, features_pro, feature_list_pro = preprocess_single_population(covari_pro)\n",
    "    splits = 8\n",
    "    train_features, test_features, train_labels, test_labels = k_fold(features_pro, labels_pro, splits)\n",
    "    hyperparameters = {\n",
    "    'n_estimators': 240,\n",
    "    'max_features': 'sqrt',\n",
    "    'max_depth': 10,\n",
    "    'random_state': 33\n",
    "    }   \n",
    "    model_training(train_features, train_labels, test_features, test_labels, hyperparameters)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
