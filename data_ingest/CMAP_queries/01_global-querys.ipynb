{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "![Python logo](https://cmap.readthedocs.io/en/latest/_static/CMAP_logos/CMAP_logo_High_Res.png) \n",
    "# In this notebook we will download enviormental data Using [Simons CMAP](https://simonscmap.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will create a dataframe that has all the latitude and longitude values that we want to sample, and then use these as targets to sample CMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a working directory\n",
    "#!pip install GitPython\n",
    "import git\n",
    "import os\n",
    "\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "\n",
    "\n",
    "os.chdir(repo.working_tree_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install global_land_mask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from global_land_mask import globe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a df that has every lat/lon point we want to sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_list = list(range(-80,81,1))\n",
    "lon_list = list(range(-180,181,1))\n",
    "\n",
    "lat = []\n",
    "lon = []\n",
    "\n",
    "for i in lat_list:\n",
    "    for j in lon_list:\n",
    "        if not globe.is_land(i,j):\n",
    "            lat.append(i)\n",
    "            lon.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lat  lon\n",
      "0      -80 -180\n",
      "1      -80 -179\n",
      "2      -80 -178\n",
      "3      -80 -177\n",
      "4      -80 -176\n",
      "...    ...  ...\n",
      "39989   80  176\n",
      "39990   80  177\n",
      "39991   80  178\n",
      "39992   80  179\n",
      "39993   80  180\n",
      "\n",
      "[39994 rows x 2 columns]\n",
      "lat    int64\n",
      "lon    int64\n",
      "dtype: object\n",
      "lat    float64\n",
      "lon    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "predictors = pd.DataFrame({'lat':lat,'lon':lon})\n",
    "print(predictors)\n",
    "print(predictors.dtypes)\n",
    "predictors['lat'] = predictors['lat'].astype('float64')\n",
    "predictors['lon'] = predictors['lon'].astype('float64')\n",
    "print(predictors.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Picking an arbitrary date and time to sample, this can be changed but you will have to re-sample CMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors['date'] = '2023-04-10'\n",
    "predictors['date'] = pd.to_datetime(predictors['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ephem\n",
    "# Finding the time in GMT that correstponds to the sunrise at the given location\n",
    "def find_sunrise(row):\n",
    "    obs = ephem.Observer()\n",
    "    obs.lat = str(row['lat'])\n",
    "    obs.long = str(row['lon'])\n",
    "    obs.date = row['date']\n",
    "\n",
    "\n",
    "    sunrise = str(obs.previous_rising(ephem.Sun()))\n",
    "    return sunrise\n",
    "\n",
    "predictors['sunrise'] = predictors.apply(find_sunrise, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lat    lon       date             sunrise                time\n",
      "0     -80.0 -180.0 2023-04-10 2023-04-09 20:52:39 2023-04-10 00:52:39\n",
      "1     -80.0 -179.0 2023-04-10 2023-04-09 20:48:37 2023-04-10 00:48:37\n",
      "2     -80.0 -178.0 2023-04-10 2023-04-09 20:44:35 2023-04-10 00:44:35\n",
      "3     -80.0 -177.0 2023-04-10 2023-04-09 20:40:33 2023-04-10 00:40:33\n",
      "4     -80.0 -176.0 2023-04-10 2023-04-09 20:36:32 2023-04-10 00:36:32\n",
      "...     ...    ...        ...                 ...                 ...\n",
      "39989  80.0  176.0 2023-04-10 2023-04-09 14:25:26 2023-04-09 18:25:26\n",
      "39990  80.0  177.0 2023-04-10 2023-04-09 14:21:29 2023-04-09 18:21:29\n",
      "39991  80.0  178.0 2023-04-10 2023-04-09 14:17:31 2023-04-09 18:17:31\n",
      "39992  80.0  179.0 2023-04-10 2023-04-09 14:13:34 2023-04-09 18:13:34\n",
      "39993  80.0  180.0 2023-04-10 2023-04-09 14:09:37 2023-04-09 18:09:37\n",
      "\n",
      "[39994 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "predictors['sunrise'] = pd.to_datetime(predictors['sunrise'])\n",
    "# we will predict at 4 hours past sunrise at every location\n",
    "predictors['time'] = predictors['sunrise'] + pd.Timedelta(hours=4)\n",
    "\n",
    "print(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the standard depth for Seaflow measurements\n",
    "predictors['depth'] = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(predictors, 'data_ingest/data/original/predictors.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling CMAP\n",
    "We will be using the exact same variables that we used for the SeaFlow data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycmap\n",
    "api = pycmap.API(token='<8f086ef3-74b5-44a8-9e11-6135f4cacaf1>')\n",
    "predictors['time'] = predictors['time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alk = api.query(\n",
    "    '''\n",
    "    SELECT month, lat, lon, depth, ALK_darwin_clim FROM tblDarwin_Nutrient_Climatology\n",
    "    WHERE\n",
    "    lat >= -80 AND lat <= 80 AND\n",
    "    lon >= -180 AND lon <= 180 AND\n",
    "    month = 4 AND\n",
    "    depth > 4 AND depth < 6\n",
    "    ORDER BY lat, lon\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = api.query(\n",
    "    '''\n",
    "    SELECT [time], lat, lon, sss_smap FROM tblSSS_NRT_cl1\n",
    "    WHERE\n",
    "    lat >= -80 AND lat <= 80 AND\n",
    "    lon >= -180 AND lon <= 180 AND\n",
    "    [time] >= '2023-04-09' AND [time] < '2023-04-12'\n",
    "    ORDER BY [time], lat, lon\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = api.query(\n",
    "    '''\n",
    "    SELECT [time], lat, lon, sst FROM tblSST_AVHRR_OI_NRT\n",
    "    WHERE\n",
    "    lat >= -80 AND lat <= 80 AND\n",
    "    lon >= -180 AND lon <= 180 AND\n",
    "    [time] >= '2023-04-10' AND [time] < '2023-04-11'\n",
    "    ORDER BY [time], lat, lon\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pisces = api.query(\n",
    "    '''\n",
    "    SELECT [time], lat, lon, fe, o2, no3, po4, si FROM tblPisces_Forecast_cl1\n",
    "    WHERE\n",
    "    lat >= -80 AND lat <= 80 AND\n",
    "    lon >= -180 AND lon <= 180 AND\n",
    "    ROUND(lat) = lat AND\n",
    "    ROUND(lon) = lon AND\n",
    "    [time] >= '2023-04-10' AND [time] < '2023-04-11' AND\n",
    "    depth > 4 AND depth < 6\n",
    "    ORDER BY [time], lat, lon\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss_table = pa.Table.from_pandas(sss)\n",
    "sst_table = pa.Table.from_pandas(sst)\n",
    "alk_table = pa.Table.from_pandas(alk)\n",
    "pisces_table = pa.Table.from_pandas(pisces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(sss_table, 'data_ingest/data/original/sss.parquet')\n",
    "pq.write_table(sst_table, 'data_ingest/data/original/sst.parquet')\n",
    "pq.write_table(alk_table, 'data_ingest/data/original/alk.parquet')\n",
    "pq.write_table(pisces_table, 'data_ingest/data/original/pisces.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.to_csv(alk, 'data_ingest/data/original/alk.csv', index=False)\n",
    "# pd.DataFrame.to_csv(sss, 'data_ingest/data/original/sss.csv', index=False)\n",
    "# pd.DataFrame.to_csv(sst, 'data_ingest/data/original/sst.csv', index=False)\n",
    "# pd.DataFrame.to_csv(pisces, 'data_ingest/data/original/pisces.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
