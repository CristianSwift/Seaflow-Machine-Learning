{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is the last step in preparing the data the Random Forest Regressors for Each population to Predict Biomass\n",
    "\n",
    " Here we will seperate the dataframes by population, prepare split features (variables used for prediction) and the label (what we are trying to predict, biomass).\n",
    "\n",
    "This notebook also includes a few functions we will use within the notebook and within each population's random forest model building notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set a working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a working directory\n",
    "#!pip install GitPython\n",
    "import git\n",
    "import os\n",
    "\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "\n",
    "\n",
    "os.chdir(repo.working_tree_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cruise</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>biomass_pro</th>\n",
       "      <th>biomass_syn</th>\n",
       "      <th>biomass_pico</th>\n",
       "      <th>biomass_croco</th>\n",
       "      <th>ALK</th>\n",
       "      <th>sss</th>\n",
       "      <th>sst</th>\n",
       "      <th>Fe</th>\n",
       "      <th>O2</th>\n",
       "      <th>NO3</th>\n",
       "      <th>PO4</th>\n",
       "      <th>Si</th>\n",
       "      <th>hours_since_sunrise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-22 22:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.343400</td>\n",
       "      <td>-158.273700</td>\n",
       "      <td>4.024661</td>\n",
       "      <td>0.337763</td>\n",
       "      <td>0.555395</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>1952.6418</td>\n",
       "      <td>34.571716</td>\n",
       "      <td>25.653118</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>6.129444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-22 23:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.343533</td>\n",
       "      <td>-158.273744</td>\n",
       "      <td>4.167834</td>\n",
       "      <td>0.413687</td>\n",
       "      <td>0.720884</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>1952.6418</td>\n",
       "      <td>34.571716</td>\n",
       "      <td>25.653118</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>7.129444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-23 00:00:00</td>\n",
       "      <td>KM1508</td>\n",
       "      <td>21.346175</td>\n",
       "      <td>-158.274150</td>\n",
       "      <td>4.654360</td>\n",
       "      <td>0.654208</td>\n",
       "      <td>0.635654</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>1952.6418</td>\n",
       "      <td>34.609317</td>\n",
       "      <td>25.646243</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>216.794167</td>\n",
       "      <td>4.269278e-07</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>9.464704</td>\n",
       "      <td>8.129722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  cruise        lat         lon  biomass_pro  \\\n",
       "0 2015-05-22 22:00:00  KM1508  21.343400 -158.273700     4.024661   \n",
       "1 2015-05-22 23:00:00  KM1508  21.343533 -158.273744     4.167834   \n",
       "2 2015-05-23 00:00:00  KM1508  21.346175 -158.274150     4.654360   \n",
       "\n",
       "   biomass_syn  biomass_pico  biomass_croco        ALK        sss        sst  \\\n",
       "0     0.337763      0.555395       0.009181  1952.6418  34.571716  25.653118   \n",
       "1     0.413687      0.720884       0.013144  1952.6418  34.571716  25.653118   \n",
       "2     0.654208      0.635654       0.008443  1952.6418  34.609317  25.646243   \n",
       "\n",
       "         Fe          O2           NO3       PO4        Si  hours_since_sunrise  \n",
       "0  0.000088  216.794167  4.269278e-07  0.345151  9.464704             6.129444  \n",
       "1  0.000088  216.794167  4.269278e-07  0.345151  9.464704             7.129444  \n",
       "2  0.000088  216.794167  4.269278e-07  0.345151  9.464704             8.129722  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "covari_path = 'data_ingest/data/modified/RF_ready_covari.csv'\n",
    "#using pandas to read in as a df\n",
    "covari = (pd.read_csv(covari_path,parse_dates=[0]))\n",
    "covari = covari.drop(columns = ['vgos', 'ugos'])\n",
    "#taking a peak at the data\n",
    "covari.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have data for 4 types of phytoplankton, here we will split the df into one df per population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "covari_pro = covari.drop(columns=['biomass_pico','biomass_croco','biomass_syn'])\n",
    "covari_syn = covari.drop(columns=['biomass_pico','biomass_croco','biomass_pro'])\n",
    "covari_pico = covari.drop(columns=['biomass_syn','biomass_croco','biomass_pro'])\n",
    "covari_croco = covari.drop(columns=['biomass_pico','biomass_syn','biomass_pro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_dfer(covari_pop, pop_name):\n",
    "    \"\"\"\n",
    "    This function removes population names from the columns of each df\n",
    "    \"\"\"\n",
    "    df = covari_pop\n",
    "    pop_name = pop_name\n",
    "    df.rename(columns=lambda x: x.replace('_'+pop_name, ''), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing population names so columns are consistent accross dataframes\n",
    "population_dfer(covari_syn, 'syn')\n",
    "population_dfer(covari_pro, 'pro')\n",
    "population_dfer(covari_pico, 'pico')\n",
    "population_dfer(covari_croco, 'croco')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "covari_syn = covari_syn.loc[covari_syn['cruise']!= 'RR2106']\n",
    "covari_pico = covari_pico.loc[covari_pico['cruise']!= 'RR2106']\n",
    "covari_syn = covari_syn.loc[covari_syn['cruise'] != 'RR1814']\n",
    "covari_pico = covari_pico.loc[covari_pico['cruise'] != 'RR1814']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_single_population(covari_population, drop, cols_drop):\n",
    "    \"\"\"\n",
    "    Takes the population dataframe and returns a dataframe that\n",
    "    only includes the selected population's rows, a list of labels (biomass values associated with the dataframe)\n",
    "    and a list of all of the features.\n",
    "    \"\"\"\n",
    "    # Selecting the population based on the provided name\n",
    "    pop_df = covari_population.copy()\n",
    "    if drop:\n",
    "        pop_df.drop(columns=cols_drop, inplace=True)\n",
    "\n",
    "    # Creating the labels and features for the population\n",
    "    labels = np.array(pop_df.biomass)\n",
    "    labels = np.delete(labels, 0, 0)\n",
    "    features = pop_df.drop(['time', 'biomass', 'lat', 'lon', 'cruise'], axis=1)\n",
    "    # Saving feature names for later use\n",
    "    feature_list = list(features.columns)\n",
    "    features = features.to_numpy()\n",
    "    features = np.delete(features, 0, 0)\n",
    "    return pop_df, labels, features, feature_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the preprocess_single_population function for all of the populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a df, labels and features for the observed Prochlorooccus\n",
    "\n",
    "drop = False\n",
    "pro_df, labels_pro, features_pro, feature_list_pro = preprocess_single_population(covari_pro, drop, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a df, labels and features for the observed Synechoccoccus\n",
    "\n",
    "\n",
    "syn_df, labels_syn, features_syn, feature_list_syn = preprocess_single_population(covari_syn, drop, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a df, labels and features for the observed Picoeukaryotes\n",
    "\n",
    "\n",
    "pico_df, labels_pico, features_pico, feature_list_pico = preprocess_single_population(covari_pico, drop, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a df, labels and features for the observed Nanoeukaryotes\n",
    "\n",
    "\n",
    "croco_df, labels_croco, features_croco, feature_list_croco = preprocess_single_population(covari_croco, drop, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a function for finding the optimal testing to training ratio\n",
    "\n",
    "Used in specific random forest model notebooks. This function graphs the Root Mean Square Error (RMSE) vs. the testing to training ratio for data used in the model.population's model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def testing_training_ratio(features, labels, feature_list, title_prefix):\n",
    "    \"\"\"\n",
    "    This function uses K-fold cross validation to split the training and test sets, each population specific notebook will use this function\n",
    "    \"\"\"\n",
    "    # Graphs the RMSE of different testing and training ratios\n",
    "    RMSEs = {'Test_Ratio':[], 'RMSE': []}\n",
    "    #define number of folds to try\n",
    "    splits = [2,4,6,8,12,16]\n",
    "    # Loop through the number of splits\n",
    "    for n in splits:\n",
    "        n_splits = n\n",
    "        kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "        #fitting the models, making predictions and calculating RMSE\n",
    "        for train_index, test_index in kf.split(features):\n",
    "            train_features, test_features = features[train_index], features[test_index]\n",
    "            train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "\n",
    "            rf = RandomForestRegressor(n_estimators = 80, max_depth= 20, max_features='sqrt', random_state = 42)\n",
    "            rf.fit(train_features, train_labels)\n",
    "\n",
    "            # Use the forest's predict method on the test data\n",
    "            predictions = rf.predict(test_features)\n",
    "\n",
    "            # Calculate the absolute errors\n",
    "            errors = abs(predictions - test_labels)\n",
    "\n",
    "            # Finding the root mean square error (RMSE)\n",
    "            RMSE = mean_squared_error(test_labels, predictions, squared=False) #setting squared=False gives us RMSE not MSE\n",
    "            RMSEs['RMSE'].append(RMSE)\n",
    "            RMSEs['Test_Ratio'].append(1/n_splits)  # The test ratio for n-fold cross-validation is 1/n_splits\n",
    "   \n",
    "    test_ratios = RMSEs['Test_Ratio']\n",
    "    rmse_values = RMSEs['RMSE']\n",
    "\n",
    "    # Create a line plot\n",
    "    plt.figure(figsize=(10, 6))  \n",
    "    plt.plot(test_ratios, rmse_values, marker='o')\n",
    "\n",
    "   \n",
    "    plt.fill_between(test_ratios, rmse_values, alpha=0.3)\n",
    "    \n",
    "    plt.xlabel('Testing:Training Ratio', fontsize=15)\n",
    "    plt.ylabel('RMSE of Biomass (pgC/L)fn', fontsize=15)\n",
    "    plt.title(f\"{title_prefix} - RMSE of Biomass vs. Testing: Training Ratio\", fontsize=22)\n",
    "\n",
    "    plt.xlim(0, 1)  \n",
    "    \n",
    "    plt.xticks([i/10 for i in range(11)])  # Set the x-axis tick locations at 0.1 increments\n",
    "    plt.gca().invert_xaxis()\n",
    "\n",
    "    \n",
    "    plt.grid(True) \n",
    "    \n",
    "    plt.tight_layout()  # Improves spacing between the plot elements\n",
    "    plt.savefig(f\"figures/{title_prefix}/RMSEsByFolds.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    return RMSEs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_training_ratio_random(features, labels, feature_list, title_prefix):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import matplotlib.pyplot as plt\n",
    "    \"\"\"\n",
    "    Used in specific random forest model notebooks. This function graphs the Root Mean Square Error (RMSE) vs.\n",
    "    the ratio to testing to training data. \n",
    "    \"\"\"\n",
    "    # Graphs the RMSE of differnt testing and training ratios\n",
    "    RMSEs = {'Test_Ratio':[], 'RMSE': []}\n",
    "    \n",
    "    range_list = [i / 20.0 for i in range(1, 19)] + [0.9][:-1] #prints 0.9 twice so I use all but last value\n",
    "\n",
    "    for fifth in range_list:\n",
    "        fifth = round(fifth, ndigits=2)\n",
    "        RMSEs['Test_Ratio'].append(fifth)\n",
    "        #using train_test_split to manipulate the training to testing ratio\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "            features, labels, test_size = fifth, random_state = 42\n",
    "            \n",
    "        )\n",
    "        rf = RandomForestRegressor(n_estimators = 80, max_depth = 10, max_features='sqrt', random_state = 42)\n",
    "        rf.fit(train_features, train_labels)\n",
    "        \n",
    "        \n",
    "        # Convert test_features to a DataFrame\n",
    "        test_features_df = pd.DataFrame(test_features, columns=feature_list)\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions = rf.predict(test_features)\n",
    "\n",
    "        # Create a new Series with predicted values and index from test_features_df\n",
    "        predic_biomass = pd.Series(predictions, index=test_features_df.index)\n",
    "\n",
    "        # Assign the new Series to the DataFrame using .loc\n",
    "        test_features_df.loc[:, 'Prediction'] = predic_biomass\n",
    "\n",
    "        # Calculate the absolute errors\n",
    "        errors = abs(predictions - test_labels)\n",
    "\n",
    "        # Finding the root mean square error (RMSE)\n",
    "\n",
    "        # RMSE give realtively high weight to large errors \n",
    "        RMSE = mean_squared_error(test_labels, predictions, squared=False) #setting squared=False gives us RMSE not MSE\n",
    "        RMSEs['RMSE'].append(RMSE)\n",
    "        \n",
    "    \n",
    "    # Extract Test Ratios and RMSEs from the dictionary\n",
    "    test_ratios = RMSEs['Test_Ratio']\n",
    "    rmse_values = RMSEs['RMSE']\n",
    "\n",
    "    # Create a line plot\n",
    "    plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "    plt.plot(test_ratios, rmse_values, marker='o')\n",
    "\n",
    "    # Fill the area under the curve\n",
    "    plt.fill_between(test_ratios, rmse_values, alpha=0.3)\n",
    "    \n",
    "    plt.xlabel('Testing:Training Ratio', fontsize=15)\n",
    "    plt.ylabel('RMSE of Biomass (pgC/L)fn', fontsize=15)\n",
    "    plt.title(f\"{title_prefix} - RMSE of Biomass vs. Testing: Training Ratio\", fontsize=22)\n",
    "\n",
    "    plt.xlim(0, 1)  # Set the x-axis limits from 0 to 1\n",
    "    \n",
    "    plt.xticks([i/10 for i in range(11)])  # Set the x-axis tick locations at 0.1 increments\n",
    "    #inversing the x axis\n",
    "    plt.gca().invert_xaxis()\n",
    "\n",
    "    \n",
    "    plt.grid(True)  # Add a grid to the plot\n",
    "    \n",
    "    plt.tight_layout()  # Improves spacing between the plot elements\n",
    "    plt.show()\n",
    "    \n",
    "    return RMSEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Functions for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_set(features, labels):\n",
    "    '''\n",
    "    This function uses a validation set to test the model\n",
    "    this uses the first 600 data points for testing and the rest for training\n",
    "    '''\n",
    "    test_features = features[:600]\n",
    "    train_features = features[600:]\n",
    "    test_labels = labels[:600]\n",
    "    train_labels = labels[600:]\n",
    "    rf = RandomForestRegressor(n_estimators = 80, max_depth = 10, max_features='sqrt', random_state = 42)\n",
    "    rf.fit(train_features, train_labels)\n",
    "    predictions = rf.predict(test_features)\n",
    "    RMSE = mean_squared_error(test_labels, predictions, squared=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test_labels, label='True Biomass')\n",
    "    plt.plot(predictions, label='Predicted Biomass')\n",
    "    plt.xlabel('Observation')\n",
    "    plt.ylabel('Biomass (pgC/L)')\n",
    "    plt.title('Validation set - True vs. Predicted Biomass')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = [0,1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(data):\n",
    "    '''\n",
    "    this function makes all of our folds the same length for k-fold cross validation\n",
    "    '''\n",
    "    # Find the length of the shortest sublist\n",
    "    min_len = min(len(sublist) for sublist in data)\n",
    "\n",
    "    # Remove data points from each sublist until they are all the same length\n",
    "    data_truncated = [sublist[:min_len] for sublist in data]\n",
    "\n",
    "    return data_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def k_fold(features, labels, splits):\n",
    "    # initialize kfold\n",
    "    n_splits = splits\n",
    "    kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "    # Initialize lists to hold training and testing data\n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    # Split the data into training and testing sets for each fold\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        train_feat, test_feat = features[train_index], features[test_index]\n",
    "        train_lab, test_lab = labels[train_index], labels[test_index]\n",
    "        \n",
    "        # Append the training and testing data for this fold to the lists\n",
    "        train_features.append(train_feat)\n",
    "        test_features.append(test_feat)\n",
    "        train_labels.append(train_lab)\n",
    "        test_labels.append(test_lab)\n",
    "    return train_features, test_features, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "def model_training(train_features, train_labels, test_features, test_labels, hyperparameters, pop_name):\n",
    "    '''\n",
    "    this function trains a random forest regressor model for each fold and saves the model\n",
    "    '''\n",
    "    # make sure features and labels are the same length\n",
    "    train_features = equalize(train_features)\n",
    "    test_features = equalize(test_features)\n",
    "    train_labels = equalize(train_labels)\n",
    "    test_labels = equalize(test_labels)\n",
    "\n",
    "\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_features = np.array(test_features)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    \n",
    "    models = []\n",
    "    n_estimators = hyperparameters['n_estimators']\n",
    "    max_depth = hyperparameters['max_depth']\n",
    "    max_features = hyperparameters['max_features']\n",
    "    if 'criterion' in hyperparameters.keys():\n",
    "        criterion = hyperparameters['criterion']\n",
    "    else:\n",
    "        criterion = 'squared_error'\n",
    "    # fit the models\n",
    "    for i in range(train_features.shape[0]):\n",
    "        \n",
    "        rf = RandomForestRegressor(n_estimators = n_estimators, max_features=max_features, max_depth = max_depth, criterion = criterion, random_state = 44)\n",
    "        \n",
    "    \n",
    "        rf.fit(train_features[i], train_labels[i])\n",
    "        \n",
    "        \n",
    "        models.append(rf)\n",
    "\n",
    "    # Save the models\n",
    "    for i, model in enumerate(models):\n",
    "        joblib.dump(model, f\"RF_models/{pop_name}/random_forest_fold_{i}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "def predict_kfold(test_features, test_labels, train_labels, train_features, pop_name):\n",
    "    \"\"\"\n",
    "    This function uses the models trained in the model_training function to predict biomass values for each fold\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "    maes = []\n",
    "    rmses = []\n",
    "    \n",
    "\n",
    "    train_features = equalize(train_features)\n",
    "    test_features = equalize(test_features)\n",
    "    train_labels = equalize(train_labels)\n",
    "    test_labels = equalize(test_labels)\n",
    "\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_features = np.array(test_features)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    for i in range(test_features.shape[0]):\n",
    "        # Load the model for this fold\n",
    "        rf = joblib.load(f\"RF_models/{pop_name}/random_forest_fold_{i}.joblib\")\n",
    "        \n",
    "        # Use the model to predict on the test data for this fold\n",
    "        preds = rf.predict(test_features[i])\n",
    "        \n",
    "        # Calculate the errors\n",
    "        mae = mean_absolute_error(test_labels[i], preds)\n",
    "        RMSE = mean_squared_error(test_labels[i], preds, squared=False)\n",
    "\n",
    "        # Append the predictions and errors to the lists\n",
    "        predictions.append(preds)\n",
    "        maes.append(mae)\n",
    "        rmses.append(RMSE)\n",
    "        # Save the predictions for each fold\n",
    "        data = {'predictions': preds,\n",
    "            'reals' : test_labels[i]}\n",
    "        \n",
    "        # for key, value in data.items():\n",
    "        #     print(f\"Number of elements in {key}: {np.size(value)}\")\n",
    "        \n",
    "        actual = pd.DataFrame(data)\n",
    "        actual.to_csv(f'data_ingest/data/modified/actual_{pop_name}{i}.csv', index=False)\n",
    "\n",
    "\n",
    "    # Convert lists of arrays to 2D arrays\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    maes = np.array(maes)\n",
    "    rmse = np.mean(rmses)\n",
    "    rmses = np.array(rmses)\n",
    "    #rmse = np.sqrt(np.mean(rmses**2))\n",
    "\n",
    "    # Print the mean absolute errors and root mean square errors\n",
    "    return predictions, maes, rmses, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "#suppress future warnings (since we are version controlled and don't need to see them)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "def plot_predictions(pop_name):\n",
    "    \"\"\"\n",
    "    This function plots the predicted vs. actual biomass values for each fold\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(8,14))\n",
    "\n",
    "\n",
    "    for i, f in enumerate(fold):\n",
    "        actual = pd.read_csv(f'data_ingest/data/modified/actual_{pop_name}{i}.csv')\n",
    "\n",
    "        plt.subplot(4, 2, i+1)  # Create a subplot for each fold\n",
    "\n",
    "        sns.kdeplot(x='reals', y='predictions', data=actual, fill=True, cmap=\"Reds\", thresh=0.05,)\n",
    "        plt.plot([0, 1], [0, 1], transform=plt.gca().transAxes, ls='--', c='black')\n",
    "        plt.xlim(0, 20)\n",
    "        plt.ylim(0, 20)\n",
    "        if pop_name == 'syn':\n",
    "            plt.xlim(0, 6)\n",
    "            plt.ylim(0, 6)\n",
    "        if pop_name == 'pico':\n",
    "            plt.xlim(0, 15)\n",
    "            plt.ylim(0, 15)\n",
    "        \n",
    "        plt.title(f'{pop_name} Fold {f+1}')\n",
    "        \n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout so that the plots do not overlap\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # for f in fold:\n",
    "    #     actual = pd.read_csv(f'data_ingest/data/modified/actual_pro{f}.csv')\n",
    "    #     # #Create scatter reals v preds\n",
    "    #     #sns.scatterplot(x='reals', y='predictions', data=actual)\n",
    "    #     #create density plot\n",
    "    #     sns.kdeplot(x='reals', y='predictions', data=actual, fill=True, cmap=\"Reds\", thresh=0.05,)\n",
    "    #     # Add a reference line from (0,0) to (1,1)\n",
    "    #     plt.plot([0, 1], [0, 1], transform=plt.gca().transAxes, ls='--', c='black')\n",
    "    #     plt.xlim(0, 20)\n",
    "    #     plt.ylim(0, 20)\n",
    "\n",
    "    #     # #linear regression line\n",
    "    #     # x = data['reals']\n",
    "    #     # y = data['predictions']\n",
    "    #     # slope, intercept = np.polyfit(x, y, 1)\n",
    "    #     # plt.plot(x, slope*x + intercept, color='blue', label='Linear Regression')\n",
    "        \n",
    "    #     plt.title(f'Prochlorococcus Fold {f+1}')\n",
    "    #     plt.savefig(f'figures/pro_fold{f+1}.png')\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covari_predictions(predictions, pop_name):\n",
    "    \"\"\"\n",
    "    This function merges the predictions with the original covari data\n",
    "    \"\"\"\n",
    "    if pop_name == 'pro':\n",
    "        original_df = covari_pro.reset_index()\n",
    "\n",
    "    elif pop_name == 'syn':\n",
    "        original_df = covari_syn.reset_index()\n",
    "    \n",
    "    elif pop_name == 'pico':\n",
    "        original_df = covari_pico.reset_index()\n",
    "\n",
    "    elif pop_name == 'croco':\n",
    "        original_df = covari_croco.reset_index()\n",
    "\n",
    "    \n",
    "    predicted_df = pd.DataFrame(predictions, columns=['prediction'])\n",
    "    #adding header to predictions\n",
    "    head = 'predicted'\n",
    "    header = pd.DataFrame([head], index=[0])\n",
    "    # Concatenate the new row and the existing DataFrame\n",
    "    predicted_df = pd.concat([header, predicted_df]).reset_index()\n",
    "\n",
    "    length = len(predicted_df)\n",
    "    original_df = original_df[:length]\n",
    "    predicted_df['index'] = original_df.index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Merge the two dataframes on the index\n",
    "    merged_df = pd.merge(original_df, predicted_df, on='index')\n",
    "    # Set the index back to the original column\n",
    "    merged_df = merged_df.set_index('index')\n",
    "    merged_df.head(5)\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def create_fold_predictions_time(pop_df, pop_name):\n",
    "    \"\"\"\n",
    "    Makes an actual vs prediction plot for each cruise, so we can compare real points\n",
    "    to prediction points\n",
    "    \"\"\"\n",
    "    unique_cruises = pop_df['cruise'].unique()\n",
    "\n",
    "    # Create a subplot grid\n",
    "    num_cruises = len(unique_cruises)\n",
    "    rows = int(num_cruises / 2) if num_cruises % 2 == 0 else int(num_cruises / 2) + 1\n",
    "    fig = make_subplots(rows=rows, cols=2, subplot_titles=unique_cruises)\n",
    "\n",
    "    \n",
    "    prediction_color = 'red'\n",
    "\n",
    "    colors = ['blue', 'green'] \n",
    "\n",
    "    # we will use this point counter to measure which data is from which fold\n",
    "    point_counter = 0  \n",
    "\n",
    "    y_range = [0, 100]\n",
    "    if pop_name == 'syn':\n",
    "        y_range = [0, 12]\n",
    "    if pop_name == 'pico':\n",
    "        y_range = [0, 30]\n",
    "    \n",
    "\n",
    "\n",
    "    for i, cruise in enumerate(unique_cruises):\n",
    "        cruise_df = pop_df[pop_df['cruise'] == cruise]\n",
    "\n",
    "        cruise_color_list = [colors[(point_counter + j) // 584 % len(colors)] for j in range(len(cruise_df))]\n",
    "\n",
    "        point_counter += len(cruise_df)\n",
    "\n",
    "        row = int(i / 2) + 1\n",
    "        col = i % 2 + 1\n",
    "        fig.add_trace(go.Scatter(x=cruise_df['time'], y=cruise_df['biomass'], mode='markers', name='Actual',\n",
    "                                marker=dict(color=cruise_color_list)),\n",
    "                    row=row, col=col)\n",
    "        fig.add_trace(go.Scatter(x=cruise_df['time'], y=cruise_df['prediction'], mode='lines', name='Prediction',\n",
    "                                line=dict(color=prediction_color)),\n",
    "                    row=row, col=col)\n",
    "        fig.update_xaxes(title_text='Time', row=row, col=col)\n",
    "        fig.update_yaxes(title_text='Biomass (pCg/L)', row=row, col=col)\n",
    "        fig.update_yaxes(range=y_range, row=row, col=col)\n",
    "\n",
    "    fig.update_layout(height=600 * rows, width=1200, title_text='Actual and Prediction for Each Cruise')\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_fold(folds, return_rmse):\n",
    "    train_features, test_features, train_labels, test_labels = k_fold(features_pro, labels_pro, folds)\n",
    "    model_training(train_features, train_labels, test_features, test_labels, hyperparameters={'n_estimators': 200, 'max_depth': 10, 'max_features': 'sqrt'})\n",
    "    predictions, maes, rmses, rmse = predict_kfold(test_features, test_labels, train_labels, train_features)\n",
    "    \n",
    "    print(\"The RMSE for \" + str(folds) + \" fold cross validation is:\" + str(rmse))\n",
    "    if return_rmse:\n",
    "        return rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function to plot out-of-bag error (OOB) againts number of trees in random forest model\n",
    "currently unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def plot_oob_error_vs_num_trees(train_features, train_labels, title_prefix):\n",
    "    \"\"\"\n",
    "    Developes a plot of Out of Bag (oob) error vs the number of trees grown in a random forest model. There are\n",
    "        three labeled lines within the plot one representing.\n",
    "    \n",
    "    Max features represent the amount of all features (varaibles we are predicting on) used for each \n",
    "        tree in the random forest. n = all features.\n",
    "    \n",
    "    Warm start = true:reuse the solution of the previous call to fit and add more\n",
    "        estimators to the ensemble, otherwise, just fit a whole new forest.\n",
    "        \n",
    "    oob_score = True: Use out-of-bag samples to estimate the generalization score. By default, r2_score is used.\n",
    "        Provide a callable with signature.\n",
    "    \n",
    "    random state: controls random number generator that is used to shuffle/split the data. Ensures the same\n",
    "        randomization is used each time the code is ran.\n",
    "    \n",
    "    \"\"\"\n",
    "    RANDOM_STATE = 42\n",
    "\n",
    "    ensemble_clfs = [\n",
    "        (\n",
    "            \"max_features='sqrt(n)'\",\n",
    "            RandomForestRegressor(\n",
    "                warm_start=True,\n",
    "                max_features=\"sqrt\",\n",
    "                oob_score=True,\n",
    "                random_state=RANDOM_STATE,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"max_features='1/3 n'\",\n",
    "            RandomForestRegressor(\n",
    "                warm_start=True,\n",
    "                max_features=1/3,\n",
    "                oob_score=True,\n",
    "                random_state=RANDOM_STATE,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"max_features= n\",\n",
    "            RandomForestRegressor(\n",
    "                warm_start=True,\n",
    "                max_features=None,\n",
    "                oob_score=True,\n",
    "                random_state=RANDOM_STATE,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "    min_estimators = 15\n",
    "    max_estimators = 128\n",
    "\n",
    "    for label, clf in ensemble_clfs:\n",
    "        for i in range(min_estimators, max_estimators + 1, 5):\n",
    "            oob_errors = []\n",
    "            for fold_features, fold_labels in zip(train_features, train_labels):\n",
    "                clf.set_params(n_estimators=i)\n",
    "                clf.fit(fold_features, fold_labels)\n",
    "                oob_error = 1 - clf.oob_score_\n",
    "                oob_errors.append(oob_error)\n",
    "            avg_oob_error = np.mean(oob_errors)\n",
    "            error_rate[label].append((i, avg_oob_error))\n",
    "    for label, clf_err in error_rate.items():\n",
    "        xs, ys = zip(*clf_err)\n",
    "        plt.plot(xs, ys, label=label)\n",
    "\n",
    "    plt.xlim(min_estimators, max_estimators)\n",
    "    plt.xlabel(\"# of Trees\")\n",
    "    plt.ylabel(\"OOB error rate (1 - R^2)\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.suptitle(f\"{title_prefix} - Out-of-Bag Error Rate vs. Number of Trees in Random Forest Regression\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for feature and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cruise(hyperparameters, pop_name):\n",
    "    \"\"\"\n",
    "    this function retrains the model on new hyperparameters and predicts ona single cruise (KM2010)\n",
    "    \"\"\"\n",
    "    model_training(train_features, train_labels, test_features, test_labels, hyperparameters, pop_name)\n",
    "    predictions, maes, rmses, rmse = predict_kfold(test_features, test_labels, train_labels, train_features, pop_name)\n",
    "    merged_df = covari_predictions(predictions, pop_name)\n",
    "    \n",
    "    # plot the prediction for KM2010\n",
    "    fig = go.Figure()\n",
    "    cruise_df = merged_df[merged_df['cruise'] == 'KM2010']\n",
    "    fig.add_trace(go.Scatter(x=cruise_df['time'], y=cruise_df['biomass'], mode='markers', name='Actual' , marker=dict(color='blue')))\n",
    "    fig.add_trace(go.Scatter(x=cruise_df['time'], y=cruise_df['prediction'], mode='lines', name='Prediction',\n",
    "                                line=dict(color='red')))\n",
    "    fig.update_layout(title='KM2010', xaxis_title='Time', yaxis_title='Biomass')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def feature_importance(pop_name, feature_list):\n",
    "    feature_importance = []\n",
    "    for f in fold:\n",
    "        rf = joblib.load(f\"RF_models/{pop_name}/random_forest_fold_{f}.joblib\")\n",
    "        feat_importance = pd.DataFrame(rf.feature_importances_, index=feature_list).sort_values(by=0, ascending=False)\n",
    "        feature_importance.append(feat_importance)\n",
    "    feature_importance = pd.concat(feature_importance, axis=1, keys=fold,)\n",
    "    feature_importance.columns = feature_importance.columns.droplevel(1)\n",
    "    feature_importance['mean'] = feature_importance.mean(axis=1)\n",
    "    feature_importance = feature_importance.sort_values(by='mean', ascending=False)\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    # Make a bar chart\n",
    "    plt.bar(x=feature_importance.index, height=feature_importance['mean'], orientation = 'vertical')\n",
    "    # Tick labels for x axis\n",
    "    plt.xticks(feature_importance.index, rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "# # Axis labels and title\n",
    "# plt.ylabel('Importance'); plt.title('Variable Importances for Pro RF')\n",
    "\n",
    "    # fig, axs = plt.subplots(4, 2, figsize=(10, 20))\n",
    "    # axs = axs.flatten()\n",
    "\n",
    "\n",
    "    # for i, f in enumerate(fold):\n",
    "    #     # Sort the data in descending order and plot\n",
    "    #     feature_importance[f].sort_values(ascending=False).plot(kind='bar', ax=axs[i])\n",
    "    #     axs[i].set_title(f'Fold {f+1}')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "fold = [0,1,2,3,4,5,6,7]\n",
    "def permutation_importances(population, test_features1, test_labels1, feature_list):\n",
    "    feature_importances = pd.DataFrame(index = feature_list, columns = fold)\n",
    "    feature_deviation = pd.DataFrame(index = feature_list, columns = fold)\n",
    "    for f in fold:\n",
    "        test_features_df = pd.DataFrame(test_features1[f])\n",
    "        test_labels_df = pd.DataFrame(test_labels1[f])\n",
    "        rf = joblib.load(f\"RF_models/{population}/random_forest_fold_{f}.joblib\")\n",
    "        result = permutation_importance(\n",
    "            rf, test_features_df, test_labels_df, n_repeats=10, random_state=33, scoring = 'neg_root_mean_squared_error', n_jobs=2)\n",
    "        # print(result.importances_mean)\n",
    "        feature_importances[f] = result.importances_mean\n",
    "        feature_deviation[f] = result.importances_std\n",
    "\n",
    "\n",
    "    forest_importances = feature_importances.mean(axis=1)\n",
    "    deviation = feature_deviation.mean(axis=1)\n",
    "    forest_importances = forest_importances.sort_values(ascending=False)\n",
    "    deviation = deviation[forest_importances.index]\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=deviation, ax=ax)\n",
    "    ax.set_title(\"Feature importances using permutation\")\n",
    "    ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_full(features, labels, feature_list):\n",
    "    rf = RandomForestRegressor(n_estimators = 120, max_features='sqrt', max_depth = 12, random_state = 44)\n",
    "        \n",
    "    \n",
    "    rf.fit(features, labels)\n",
    "\n",
    "    result = permutation_importance(\n",
    "        rf, features, labels, n_repeats=10, random_state=33, scoring = 'neg_root_mean_squared_error', n_jobs=2)\n",
    "    forest_importances = result.importances_mean\n",
    "    forest_importances = pd.Series(forest_importances, index=feature_list)\n",
    "    forest_importances = forest_importances.sort_values(ascending=False)\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "    ax.set_title(\"Feature importances using permutation\")\n",
    "    ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def grid_search_hyperparams(param_grid, metrics, features, labels):\n",
    "    \"\"\"\n",
    "    Uses a function from sklearn to test different combinations of hyperparameters and find the ones \n",
    "    with the lowest value of the specified test metric.  Do not rely on these hyperparameters as the best\n",
    "    for prediction, as we need the model to be more flexible than is represented by the test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    numK=[8]\n",
    "\n",
    "    for i in numK:\n",
    "        for metric in metrics:\n",
    "            grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=i, scoring=metric, error_score='raise', verbose=1)\n",
    "\n",
    "            grid_search.fit(features, labels)\n",
    "\n",
    "            # Get the best hyperparameters\n",
    "            best_params = grid_search.best_params_\n",
    "\n",
    "            print(\"Best hyperparameters for \", metric, f\"are: {best_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
